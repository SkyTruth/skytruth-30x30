{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "scripts_dir = Path(\"../../\").joinpath(\"src\")\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.insert(0, scripts_dir.resolve().as_posix())\n",
    "\n",
    "from helpers.strapi import Strapi\n",
    "from helpers.settings import get_settings, Settings\n",
    "from helpers.file_handler import FileConventionHandler\n",
    "from helpers.utils import download_and_unzip_if_needed, writeReadGCP\n",
    "\n",
    "from pipelines.output_schemas import (\n",
    "    FPLSchema,\n",
    "    ProtectionLevelSchema,\n",
    "    MPAsSchema,\n",
    "    HabitatsSchema,\n",
    "    LocationSchema,\n",
    "    ProtectedAreaExtentSchema,\n",
    ")\n",
    "from pipelines.processors import (\n",
    "    add_envelope,\n",
    "    add_location_iso,\n",
    "    expand_multiple_locations,\n",
    "    add_region_iso,\n",
    "    calculate_eez_area,\n",
    "    add_bbox,\n",
    "    add_groups_and_members,\n",
    "    add_location_name,\n",
    "    output,\n",
    "    clean_geometries,\n",
    "    filter_by_exluding_propossed_mpas,\n",
    "    spatial_join,\n",
    "    process_mpa_data,\n",
    "    assign_iso3,\n",
    "    calculate_global_area,\n",
    "    separate_parent_iso,\n",
    "    calculate_stats_cov,\n",
    "    coverage_stats,\n",
    "    mpaatlas_filter_stablishment,\n",
    "    process_mpaatlas_data,\n",
    "    calculate_stats,\n",
    "    fix_monaco,\n",
    "    batch_export,\n",
    "    calculate_area,\n",
    "    define_is_child,\n",
    "    set_child_id,\n",
    "    add_child_parent_relationship,\n",
    "    columns_to_lower,\n",
    "    extract_wdpaid_mpaatlas,\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"fiona\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysettings = get_settings()\n",
    "prev_step = \"preprocess\"\n",
    "current_step = \"stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_eez = \"eez\"\n",
    "pipe_eez_dir = FileConventionHandler(pipe_eez)\n",
    "pipe_gadm = \"gadm\"\n",
    "pipe_gadm_dir = FileConventionHandler(pipe_gadm)\n",
    "\n",
    "output_file = pipe_gadm_dir.get_processed_step_path(current_step).joinpath(\"locations.json\")\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(pipe_eez_dir, prev_step, mysettings)\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(pipe_gadm_dir, prev_step, mysettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "import pandera as pa\n",
    "from pandera.typing import Index, Series\n",
    "from pandera.typing.geopandas import GeoDataFrame, GeoSeries\n",
    "import pandas as pd\n",
    "\n",
    "class LocationSchemaAll(pa.DataFrameModel):\n",
    "    id: Index[int] = pa.Field(gt=0, coerce=True)\n",
    "    code: Series[str] = pa.Field(coerce=True)\n",
    "    name: Series[str] = pa.Field(coerce=True)\n",
    "    totalMarineArea: Series[float] = pa.Field(ge=0, coerce=True)  # noqa: N815\n",
    "    totalLandArea: Series[float] = pa.Field(ge=0, coerce=True)  # noqa: N815\n",
    "    type: Series[str] = pa.Field(\n",
    "        unique_values_eq=[\"country\", \"worldwide\", \"region\", \"highseas\"], coerce=True\n",
    "    )\n",
    "    groups: Series[List[int]] = pa.Field(coerce=True)\n",
    "    bounds: Series[List[float]] = pa.Field(coerce=True)\n",
    "\n",
    "def calculate_gadm_area(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    glob = gpd.GeoDataFrame(\n",
    "        {\n",
    "            \"iso\": \"GLOB\",\n",
    "            \"AREA_KM2\": 134954835,\n",
    "            \"location_type\": \"worldwide\",\n",
    "            \"region\": np.nan,\n",
    "            \"geometry\": gpd.GeoSeries([gpd.GeoSeries(df[\"geometry\"]).unary_union]),\n",
    "        },\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "\n",
    "    terrestrial_areas = (\n",
    "        df\n",
    "        .dissolve(by=[\"iso\", \"region\"], aggfunc={\"AREA_KM2\": \"sum\"})\n",
    "        .reset_index()\n",
    "        .assign(location_type=\"country\")\n",
    "    )\n",
    "    regions_areas = (\n",
    "        df\n",
    "        .dissolve(by=[\"region\"], aggfunc={\"AREA_KM2\": \"sum\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"region\": \"iso\"})\n",
    "        .assign(location_type=\"region\")\n",
    "    )\n",
    "    result = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                glob,\n",
    "                regions_areas,\n",
    "                terrestrial_areas,\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        .dropna(subset=[\"iso\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    result.index = result.index + 1\n",
    "    result.index.name = \"id\"\n",
    "\n",
    "    return result.assign(id=result.index)\n",
    "\n",
    "def add_groups_and_members_land(df: pd.DataFrame | gpd.GeoDataFrame) -> pd.DataFrame | gpd.GeoDataFrame:\n",
    "    return df.assign(\n",
    "        groups=lambda row: row[[\"region\", \"location_type\"]].apply(\n",
    "            lambda x: (np.where(df.iso == x[\"region\"])[0] + 2).tolist()\n",
    "            if x[\"location_type\"] == \"country\"\n",
    "            else [],\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "def combine_bounds(marine_bounds, land_bounds):\n",
    "    # Check if marine bounds are valid\n",
    "    if isinstance(marine_bounds, list) and len(marine_bounds) == 4:\n",
    "        return marine_bounds\n",
    "    # If marine bounds are not valid, check land bounds\n",
    "    elif isinstance(land_bounds, list) and len(land_bounds) == 4:\n",
    "        return land_bounds\n",
    "    # If neither bounds are valid, return an empty list\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def combine_columns(df, col1, col2, new_col):\n",
    "    \"\"\"\n",
    "    Combine two columns in a DataFrame using combine_first and assign to a new column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the columns to combine.\n",
    "    col1 (str): The name of the first column.\n",
    "    col2 (str): The name of the second column.\n",
    "    new_col (str): The name of the new column to assign the combined result.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with the new combined column.\n",
    "    \"\"\"\n",
    "    df[new_col] = df[col1].combine_first(df[col2])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process EEZ data (marine data)\n",
    "locations = (\n",
    "    gpd.read_file(pipe_eez_dir.get_step_fmt_file_path(prev_step, \"shp\"))\n",
    "    .pipe(add_envelope)\n",
    "    .pipe(add_location_iso)\n",
    "    .pipe(expand_multiple_locations)\n",
    "    .pipe(add_region_iso, 'iso')\n",
    "    .pipe(calculate_eez_area)\n",
    "    .pipe(add_bbox)\n",
    "    .pipe(add_groups_and_members)\n",
    "    .pipe(add_location_name)\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"iso\": \"code\",\n",
    "            \"AREA_KM2\": \"totalMarineArea\",\n",
    "            \"location_type\": \"type\",\n",
    "        }\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "locations.drop(\n",
    "    columns=list(\n",
    "        set(locations.columns) -\n",
    "        set([\"code\", \"name\", \"totalMarineArea\", \"type\", \"groups\", \"bounds\", \"id\"])\n",
    "    ),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a lookup dictionary for IDs from EEZ data\n",
    "id_lookup = locations.set_index('code')['id'].to_dict()\n",
    "\n",
    "# Process GADM data (land data)\n",
    "locations_land = (\n",
    "    gpd.read_file(pipe_gadm_dir.get_step_fmt_file_path(prev_step, \"shp\"))\n",
    "    .rename(columns={\"GID_0\": \"iso\", 'area_km2': 'AREA_KM2'})\n",
    "    .pipe(add_envelope)\n",
    "    .pipe(add_region_iso, 'iso')\n",
    "    .pipe(calculate_gadm_area)\n",
    "    .pipe(add_bbox)\n",
    "    .pipe(add_groups_and_members_land)\n",
    "    .pipe(add_location_name)\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"iso\": \"code\",\n",
    "            \"AREA_KM2\": \"totalLandArea\",\n",
    "            \"location_type\": \"type\",\n",
    "        }\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Apply the EEZ IDs to the GADM dataset\n",
    "locations_land['id'] = locations_land['code'].map(id_lookup)\n",
    "\n",
    "# Identify the NaN values in the id column\n",
    "nan_mask = locations_land['id'].isna()\n",
    "\n",
    "# Generate new IDs for any GADM rows without an EEZ match\n",
    "new_ids = pd.Series(\n",
    "    range(max(id_lookup.values()) + 1, max(id_lookup.values()) + 1 + nan_mask.sum()),\n",
    "    index=locations_land[nan_mask].index\n",
    ")\n",
    "\n",
    "# Assign the new IDs to the NaN values in the id column\n",
    "locations_land['id'] = locations_land['id'].fillna(new_ids).astype(int)\n",
    "\n",
    "# Drop unnecessary columns in GADM data\n",
    "locations_land.drop(\n",
    "    columns=list(\n",
    "        set(locations_land.columns) -\n",
    "        set([\"code\", \"name\", \"totalLandArea\", \"type\", \"groups\", \"bounds\", \"id\"])\n",
    "    ),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Merge EEZ and GADM datasets\n",
    "combined_locations = pd.merge(\n",
    "    locations, locations_land,\n",
    "    on=['code', 'id'],\n",
    "    suffixes=('_marine', '_land'),\n",
    "    how='outer'  # Use 'outer' join to keep all records\n",
    ")\n",
    "\n",
    "# Replace NaN values in TotalMarineArea and TotalLandArea with 0\n",
    "combined_locations['totalMarineArea'] = combined_locations['totalMarineArea'].fillna(0)\n",
    "combined_locations['totalLandArea'] = combined_locations['totalLandArea'].fillna(0)\n",
    "combined_locations['id'] = combined_locations['id'].astype(int)\n",
    "\n",
    "# Combine bounding boxes from both datasets\n",
    "combined_locations['bounds'] = combined_locations.apply(lambda row: combine_bounds(row['bounds_marine'], row['bounds_land']), axis=1)\n",
    "\n",
    "# Combine data from land and marine\n",
    "combined_locations = combine_columns(combined_locations, 'type_marine', 'type_land', 'type')\n",
    "combined_locations = combine_columns(combined_locations, 'groups_marine', 'groups_land', 'groups')\n",
    "combined_locations = combine_columns(combined_locations, 'name_marine', 'name_land', 'name')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "combined_locations.drop(\n",
    "    columns=[col for col in combined_locations.columns if col.endswith('_marine') or col.endswith('_land')],\n",
    "    inplace=True\n",
    ")\n",
    "combined_locations = combined_locations.reset_index(drop=True)\n",
    "\n",
    "combined_locations['index'] = combined_locations['id']\n",
    "combined_locations.set_index('index', inplace=True)\n",
    "combined_locations.sort_index(inplace=True)\n",
    "\n",
    "# Step 8: Prepare final JSON output (stored in gadm folder)\n",
    "output_locations_combined = {\n",
    "    \"version\": 2,\n",
    "    \"data\": {\n",
    "        \"api::location.location\": LocationSchemaAll(pd.DataFrame(combined_locations)).to_dict(\n",
    "            orient=\"index\"\n",
    "        )\n",
    "    },\n",
    "}\n",
    "\n",
    "# Step 9: Write the output to a JSON file (stored in gadm folder)\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(output_locations_combined, f)\n",
    "\n",
    "del output_locations_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create locations_code (stored in gadm folder)\n",
    "(combined_locations[['id', 'code']]\n",
    " .to_csv(pipe_gadm_dir.get_processed_step_path(current_step)\n",
    "     .joinpath('locations_code.csv'), index=False))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
