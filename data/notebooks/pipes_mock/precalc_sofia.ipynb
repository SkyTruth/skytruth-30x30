{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import json\n",
    "import dotenv\n",
    "import os\n",
    "import logging\n",
    "from typing import Tuple, List, Union\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "from itertools import product\n",
    "from shapely.geometry import box\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "scripts_dir = Path(\".\").joinpath(\"src\")\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.insert(0, scripts_dir.resolve().as_posix())\n",
    "\n",
    "from helpers.strapi import Strapi\n",
    "from helpers.settings import get_settings, Settings\n",
    "from helpers.file_handler import FileConventionHandler\n",
    "from helpers.utils import download_and_unzip_if_needed, writeReadGCP\n",
    "\n",
    "from pipelines.output_schemas import (\n",
    "    FPLSchema,\n",
    "    ProtectionLevelSchema,\n",
    "    MPAsSchema,\n",
    "    HabitatsSchema,\n",
    "    LocationSchema,\n",
    "    ProtectedAreaExtentSchema,\n",
    ")\n",
    "from pipelines.processors import (\n",
    "    add_envelope,\n",
    "    add_location_iso,\n",
    "    expand_multiple_locations,\n",
    "    add_region_iso,\n",
    "    calculate_eez_area,\n",
    "    add_bbox,\n",
    "    add_groups_and_members,\n",
    "    add_location_name,\n",
    "    output,\n",
    "    clean_geometries,\n",
    "    filter_by_exluding_propossed_mpas,\n",
    "    spatial_join,\n",
    "    process_mpa_data,\n",
    "    assign_iso3,\n",
    "    calculate_global_area,\n",
    "    separate_parent_iso,\n",
    "    calculate_stats_cov,\n",
    "    coverage_stats,\n",
    "    mpaatlas_filter_stablishment,\n",
    "    process_mpaatlas_data,\n",
    "    calculate_stats,\n",
    "    fix_monaco,\n",
    "    batch_export,\n",
    "    calculate_area,\n",
    "    define_is_child,\n",
    "    set_child_id,\n",
    "    add_child_parent_relationship,\n",
    "    columns_to_lower,\n",
    "    extract_wdpaid_mpaatlas,\n",
    "    simplify_async,\n",
    "    process_tpa_data,\n",
    "    get_matches,\n",
    "    repair_geometry, \n",
    "    arrange_dimensions, \n",
    ")\n",
    "from pipelines.utils import background\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"fiona\").setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysettings = get_settings()\n",
    "prev_step = \"preprocess\"\n",
    "current_step = \"stats\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import pandera as pa\n",
    "from pandera.typing import Index, Series\n",
    "\n",
    "def change_ata_to_abnj(df):\n",
    "    \"\"\"\n",
    "    Changes values in the parent_iso column from 'ATA' to 'ABNJ' as there is no 'ATA' stats in Protected Planet.\n",
    "    \"\"\"\n",
    "    # Count the occurrences of 'ATA'\n",
    "    count_changes = df['parent_iso'].value_counts().get('ATA', 0)\n",
    "    \n",
    "    # Replace 'ATA' with 'ABNJ'\n",
    "    df['parent_iso'] = df['parent_iso'].replace('ATA', 'ABNJ')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_total_marine_area(df):\n",
    "    # Read the JSON file\n",
    "    with open(scripts_dir.joinpath('data_commons/data/locations_all.json'), 'r') as f:\n",
    "        locations_data = json.load(f)\n",
    "    \n",
    "    # Access the nested dictionary\n",
    "    locations_dict = locations_data.get('data', {}).get('api::location.location', {})\n",
    "    \n",
    "    # Create a lookup dictionary from the nested dictionary\n",
    "    marine_area_lookup = {item['code']: item['total_marine_area'] for item in locations_dict.values()}\n",
    "    \n",
    "    # Identify the column that contains the word 'iso'\n",
    "    iso_column = [col for col in df.columns if 'iso' in col][0]\n",
    "\n",
    "    # Perform the mapping using the identified column\n",
    "    df['total_marine_area'] = df[iso_column].map(marine_area_lookup)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_total_terrestrial_area(df):\n",
    "    # Read the JSON file\n",
    "    with open(scripts_dir.joinpath('data_commons/data/locations_all.json'), 'r') as f:\n",
    "        locations_data = json.load(f)\n",
    "    \n",
    "    # Access the nested dictionary\n",
    "    locations_dict = locations_data.get('data', {}).get('api::location.location', {})\n",
    "    \n",
    "    # Create a lookup dictionary from the nested dictionary\n",
    "    marine_area_lookup = {item['code']: item['total_terrestrial_area'] for item in locations_dict.values()}\n",
    "    \n",
    "    # Identify the column that contains the word 'iso'\n",
    "    iso_column = [col for col in df.columns if 'iso' in col][0]\n",
    "\n",
    "    # Perform the mapping using the identified column\n",
    "    df['total_terrestrial_area'] = df[iso_column].map(marine_area_lookup)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_mpa_oecm_percentages(df):\n",
    "    # Calculate the total protectedAreasCount for each year and iso_3\n",
    "    total_counts = df.groupby(['year', 'iso_3'])['protectedAreasCount'].transform('sum')\n",
    "\n",
    "    # Calculate the counts for PA_DEF == 0 and PA_DEF == 1\n",
    "    df['oecm_count'] = df['protectedAreasCount'].where(df['PA_DEF'] == 0, 0)\n",
    "    df['pa_count'] = df['protectedAreasCount'].where(df['PA_DEF'] == 1, 0)\n",
    "\n",
    "    # Calculate the percentages\n",
    "    df['oecms'] = df.groupby(['year', 'iso_3'])['oecm_count'].transform('sum') / total_counts * 100\n",
    "    df['pas'] = df.groupby(['year', 'iso_3'])['pa_count'].transform('sum') / total_counts * 100\n",
    "\n",
    "    # Aggregate the results and fill NaN values with 0\n",
    "    final_df = df.groupby(['year', 'iso_3']).agg(\n",
    "        area=('area', 'sum'),\n",
    "        protected_areas_count=('protectedAreasCount', 'sum'),\n",
    "        oecms=('oecms', 'first'),\n",
    "        pas=('pas', 'first')\n",
    "    ).reset_index().fillna(0)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def calculate_pa_def_percentages(df: pd.DataFrame, iso_col: str = \"iso_3\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the percentages for each PA_DEF value.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the cumulative counts of PA_DEF values.\n",
    "    iso_col (str): The column name for the iso_3 values. Default is \"iso_3\".\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the percentages of PA_DEF values for each iso_3 and each year.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['protected_areas_count'] = df['0'] + df['1']\n",
    "    df['oecms'] = (df['0'] / df['protected_areas_count']) * 100\n",
    "    df['pas'] = (df['1'] / df['protected_areas_count']) * 100\n",
    "\n",
    "    df = df.drop(columns=['0', '1'], errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_coverage_percentage_mpatlas(df):\n",
    "    df['percentage'] = (df['area_km2'] / df['total_marine_area']) * 100\n",
    "    return df\n",
    "\n",
    "def calculate_coverage_percentage_pa(df):\n",
    "    if 'total_marine_area' in df.columns:\n",
    "        df['coverage'] = (df['protected_area'] / df['total_marine_area']) * 100\n",
    "    elif 'total_terrestrial_area' in df.columns:\n",
    "        df['coverage'] = (df['protected_area'] / df['total_terrestrial_area']) * 100\n",
    "    else:\n",
    "        df['coverage'] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_global_contribution(df):\n",
    "    if 'total_marine_area' in df.columns:\n",
    "        df['global_contribution'] = (df['protected_area'] / 361000000) * 100\n",
    "    elif 'total_terrestrial_area' in df.columns:\n",
    "        df['global_contribution'] = (df['protected_area'] / 134954835) * 100\n",
    "    else:\n",
    "        df['global_contribution'] = np.nan\n",
    "    return df\n",
    "\n",
    "def add_is_last_year(df):\n",
    "    # Find the latest year for each iso_3\n",
    "    latest_years = df.groupby('iso_3')['year'].transform('max')\n",
    "    \n",
    "    # Create the is_last_year column\n",
    "    df['is_last_year'] = df['year'] == latest_years\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_environment(df):\n",
    "    \"\"\"\n",
    "    Adds a column 'environment' based on the presence of 'totalMarineArea' or 'totalLandArea'.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with the 'environment' column added.\n",
    "    \"\"\"\n",
    "    if 'total_marine_area' in df.columns:\n",
    "        df['environment'] = 'marine'\n",
    "    elif 'total_terrestrial_area' in df.columns:\n",
    "        df['environment'] = 'terrestrial'\n",
    "    else:\n",
    "        df['environment'] = 'unknown' \n",
    "    \n",
    "    return df\n",
    "\n",
    "def coverage_stats2(\n",
    "    df: pd.DataFrame,\n",
    "    area_col: str = \"area\",\n",
    "    sort_vals: List[str] = [\"iso_3\", \"year\"],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"only relevant to get the coverage numbers for mpa\"\"\"\n",
    "    return df.assign(\n",
    "        protected_area=(\n",
    "            df.sort_values(by=sort_vals)[area_col]\n",
    "            - df.sort_values(by=sort_vals)\n",
    "            .groupby(sort_vals)[area_col]\n",
    "            .shift(-1, fill_value=0)\n",
    "            .reset_index(drop=True)\n",
    "        ).round(2),\n",
    "    )\n",
    "\n",
    "def process_mpaatlas_data(gdf: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    return (\n",
    "        gdf.dissolve(by=[\"protecti_1\", \"iso_3\"], aggfunc={\"name\": \"count\"})\n",
    "        .reset_index()\n",
    "        .pipe(calculate_area, \"area_km2\", None)\n",
    "        .drop(columns=[\"geometry\"])\n",
    "    )\n",
    "\n",
    "def separate_parent_iso(df: pd.DataFrame, iso_column=\"iso_3\", separator=\";\") -> pd.DataFrame:\n",
    "    df[iso_column] = (\n",
    "        df[iso_column].str.replace(\" \", \"\").str.replace(\":\", separator).str.split(separator)\n",
    "    )\n",
    "    return df.explode(iso_column)\n",
    "\n",
    "def output2(\n",
    "    df: pd.DataFrame, iso_column: str, rep_d: dict, rename: Dict[str, str], drop_cols: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Output function formatter for the data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        iso_column (str): The column containing the ISO codes.\n",
    "        rep_d (dict): A dictionary of values to replace.\n",
    "        rename (Dict[str, str]): A dictionary of columns to rename.\n",
    "        drop_cols (List[str]): A list of columns to drop.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    if iso_column:\n",
    "        locations_code = pd.read_csv(\n",
    "            scripts_dir.joinpath(\"data_commons/data/locations_code_all.csv\"),\n",
    "            keep_default_na=False,\n",
    "            na_values=[]\n",
    "        )\n",
    "        df = df.join(locations_code.set_index(\"code\"), on=iso_column, how=\"left\")\n",
    "    return (\n",
    "        df.replace(rep_d)\n",
    "        .rename(columns=rename)\n",
    "        .drop(columns=drop_cols)\n",
    "        .assign(\n",
    "            id=df.index + 1,\n",
    "        )\n",
    "        .set_index(\"id\")\n",
    "    )\n",
    "\n",
    "def set_child_id_pa(\n",
    "    df: pd.DataFrame | gpd.GeoDataFrame, columns: list[str] = [\"wdpa_pid\"]\n",
    ") -> pd.DataFrame | gpd.GeoDataFrame:\n",
    "    return df.assign(child_id=df[columns].bfill(axis=1)[columns[0]])\n",
    "\n",
    "def calculate_global_area_pa(\n",
    "    df: pd.DataFrame,\n",
    "    gby_col: list,\n",
    "    agg_ops: Dict[str, str] = {\"area\": \"sum\"},\n",
    "    iso_column=\"iso_3\",\n",
    ") -> pd.DataFrame:\n",
    "    global_area = df.groupby([*gby_col]).agg(agg_ops).reset_index().assign(**{iso_column: \"GLOB\"})\n",
    "    return pd.concat([global_area, df], ignore_index=True)\n",
    "\n",
    "\n",
    "def cumulative_pa_def_counts(df: pd.DataFrame, year_col: str = \"STATUS_YR\", pa_def_col: str = \"PA_DEF\", iso_col: str = \"iso_3\", start_year: int = 2010) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the cumulative number of PA_DEF values for each iso_3 and each year starting from a given year.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    year_col (str): The column name for the year. Default is \"STATUS_YR\".\n",
    "    pa_def_col (str): The column name for the PA_DEF values. Default is \"PA_DEF\".\n",
    "    iso_col (str): The column name for the iso_3 values. Default is \"iso_3\".\n",
    "    start_year (int): The starting year for cumulative counts. Default is 2010.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with cumulative counts of PA_DEF values for each iso_3 and each year.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    years = sorted(df[year_col].unique())\n",
    "\n",
    "    for year in years:\n",
    "        if year < start_year:\n",
    "            continue\n",
    "        cumulative_data = df[df[year_col] <= year]\n",
    "        pa_def_counts = cumulative_data.groupby([iso_col, pa_def_col]).size().unstack(fill_value=0)\n",
    "        pa_def_counts['year'] = year\n",
    "        results.append(pa_def_counts.reset_index())\n",
    "\n",
    "    final_results = pd.concat(results, ignore_index=True)\n",
    "    final_results = final_results.fillna(0)\n",
    "    final_results = final_results.groupby([iso_col, 'year']).sum().reset_index()\n",
    "\n",
    "    final_results['protected_areas_count'] = final_results['0'] + final_results['1']\n",
    "\n",
    "    return final_results\n",
    "\n",
    "def calculate_stats_pa(\n",
    "    df: pd.DataFrame, gby_col: list, iso_column: str, ops: dict[str, str] = {\"protected_area\": \"sum\"}\n",
    ") -> pd.DataFrame:\n",
    "    # Group by the specified columns and region, then aggregate\n",
    "    regions = (\n",
    "        df.groupby([*gby_col, \"region\"])\n",
    "        .agg(ops)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"region\": iso_column})\n",
    "    )\n",
    "\n",
    "    # Group by the specified columns and iso_column, then aggregate\n",
    "    countries = df.groupby([*gby_col, iso_column]).agg(ops).reset_index()\n",
    "\n",
    "    # Concatenate the results\n",
    "    return pd.concat([regions, countries], ignore_index=True)\n",
    "\n",
    "def calculate_stats_cov_pa(df: pd.DataFrame, gby_col: list, iso_column: str):\n",
    "    return calculate_stats_pa(df, gby_col, iso_column, {\"protected_area\": \"sum\", \"protected_areas_count\": \"sum\", \"1\": \"sum\", \"0\": \"sum\"})\n",
    "\n",
    "\n",
    "def add_region_iso2(\n",
    "    df: pd.DataFrame | gpd.GeoDataFrame, iso_column\n",
    ") -> pd.DataFrame | gpd.GeoDataFrame:\n",
    "    \n",
    "    with open(scripts_dir.joinpath('data_commons/data/regions_data2.json'), 'r') as f:\n",
    "        regions = json.load(f)\n",
    "\n",
    "    def find_region_iso(iso: str) -> Union[str, None]:\n",
    "        filtered_regions = list(filter(lambda x: iso in x[\"country_iso_3s\"], regions.get(\"data\")))\n",
    "        return filtered_regions[0][\"region_iso\"] if len(filtered_regions) > 0 else None\n",
    "\n",
    "    return df.assign(region=lambda row: row[iso_column].apply(find_region_iso))\n",
    "\n",
    "\n",
    "\n",
    "class NewProtectedAreaExtentSchema(pa.DataFrameModel):\n",
    "    id: Index[int] = pa.Field(gt=0, coerce=True)\n",
    "    location: Series[int] = pa.Field(gt=0, coerce=True)\n",
    "    protected_area: Series[float] = pa.Field(ge=0, coerce=True)\n",
    "    protected_areas_count: Series[int] = pa.Field(ge=0, coerce=True)\n",
    "    oecms: Series[float] = pa.Field(ge=0, le=100, coerce=True)\n",
    "    pas: Series[float] = pa.Field(ge=0, le=100, coerce=True)\n",
    "    coverage: Series[float] = pa.Field(ge=0, le=100, coerce=True)\n",
    "    global_contribution: Series[float] = pa.Field(ge=0, le=100, coerce=True)\n",
    "    year: Series[int] = pa.Field(ge=2000, coerce=True)\n",
    "    is_last_year: Series[bool] = pa.Field(coerce=True)\n",
    "    environment: Series[str] = pa.Field(isin=[\"marine\", \"terrestrial\"], coerce=True)\n",
    "\n",
    "class NewProtectionLevelSchema(pa.DataFrameModel):\n",
    "    id: Index[int] = pa.Field(gt=0, coerce=True)\n",
    "    location: Series[int] = pa.Field(gt=0, coerce=True)\n",
    "    mpaa_protection_level: Series[int] = pa.Field(ge=0, coerce=True)\n",
    "    year: Series[int] = pa.Field(gt=1900, coerce=True)\n",
    "    area: Series[float] = pa.Field(ge=0, coerce=True)\n",
    "    percentage: Series[float] = pa.Field(ge=0, le=100, coerce=True)\n",
    "\n",
    "class PAsSchema(pa.DataFrameModel):\n",
    "    id: Index[int] = pa.Field(gt=0, coerce=True)\n",
    "    wdpaid: Series[pd.Int64Dtype] = pa.Field(coerce=True, nullable=True)\n",
    "    child_id: Series[str] = pa.Field(coerce=True)\n",
    "    name: Series[str] = pa.Field(coerce=True)\n",
    "    year: Series[pd.Int32Dtype] = pa.Field(gt=1700, nullable=True)\n",
    "    area: Series[float] = pa.Field(ge=0, coerce=True)\n",
    "    bbox: Series[List[float]] = pa.Field(coerce=True)\n",
    "    location: Series[int] = pa.Field(ge=0, coerce=True)\n",
    "    protection_status: Series[int] = pa.Field(ge=0, nullable=True)\n",
    "    mpaa_establishment_stage: Series[pd.Int32Dtype] = pa.Field(ge=0, nullable=True, coerce=True)\n",
    "    mpaa_protection_level: Series[pd.Int32Dtype] = pa.Field(ge=0, nullable=True, coerce=True)\n",
    "    pa_iucn_category: Series[pd.Int32Dtype] = pa.Field(coerce=True, nullable=True)\n",
    "    designation: Series[str] = pa.Field(coerce=True, nullable=True)\n",
    "    is_child: Series[bool] = pa.Field(coerce=True)\n",
    "    children: Series[List[int]] = pa.Field(coerce=True, nullable=True)\n",
    "    data_source: Series[int] = pa.Field(coerce=True)\n",
    "    coverage: Series[float] = pa.Field(ge=0, le=100, nullable=True)\n",
    "    environment: Series[str] = pa.Field(isin=[\"marine\", \"terrestrial\"], coerce=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for terrestrial processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for pa terrestrial processing\n",
    "\n",
    "def split_by_year(\n",
    "    gdf: gpd.GeoDataFrame, year_col: str = \"STATUS_YR\", year_val: int = 2010\n",
    ") -> List[gpd.GeoDataFrame]:\n",
    "    \"\"\"Split data by year. relevant for MPA data.(coverage indicator)\"\"\"\n",
    "    prior_2010 = (\n",
    "        gdf[gdf[year_col] <= year_val][[\"iso_3\", \"STATUS_YR\", \"geometry\"]]\n",
    "        .dissolve(\n",
    "            by=[\"iso_3\"],\n",
    "        )\n",
    "        .assign(year=2010)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    after_2010 = (\n",
    "        gdf[gdf[\"STATUS_YR\"] > 2010][[\"iso_3\", \"STATUS_YR\", \"geometry\"]]\n",
    "        .rename(columns={\"STATUS_YR\": \"year\"})\n",
    "    )\n",
    "    return [prior_2010, after_2010]\n",
    "\n",
    "\n",
    "def create_grid(bounds: Tuple[float, float, float, float], cell_size: int = 1) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Create a grid of cells for a given GeoDataFrame\"\"\"\n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    x = np.arange(minx, maxx, cell_size)\n",
    "    y = np.arange(miny, maxy, cell_size)\n",
    "    polygons = [\n",
    "        {\n",
    "            \"geometry\": box(i, j, i + cell_size, j + cell_size),\n",
    "            \"cell_id\": f\"{i}_{j}\",\n",
    "        }\n",
    "        for i, j in product(x, y)\n",
    "    ]\n",
    "    return gpd.GeoDataFrame(polygons)\n",
    "\n",
    "\n",
    "def subdivide_grid(\n",
    "    grid_gdf: gpd.GeoDataFrame, gdf: gpd.GeoDataFrame, max_cellsize: float, max_complexity: int\n",
    ") -> List:\n",
    "    subdivided_elements = []\n",
    "    for grid_element in grid_gdf.geometry:\n",
    "        candidates = get_matches(grid_element, gdf)\n",
    "        density = len(candidates)\n",
    "        if density > max_complexity:\n",
    "            \n",
    "            subdivision_cellsize = max_cellsize / 2\n",
    "            # Subdivide the grid element recursively\n",
    "            subgrid = create_grid(grid_element.bounds, subdivision_cellsize)\n",
    "            subdivided_elements.extend(\n",
    "                subdivide_grid(subgrid, gdf, subdivision_cellsize, max_complexity)\n",
    "            )\n",
    "        elif density > 0:\n",
    "            subdivided_elements.append(grid_element)\n",
    "\n",
    "    return subdivided_elements\n",
    "\n",
    "\n",
    "def create_density_based_grid(\n",
    "    gdf: gpd.GeoDataFrame, max_cellsize: int = 10, max_complexity: int = 10000\n",
    ") -> gpd.GeoDataFrame:\n",
    "    # Get the bounds of the GeoDataFrame\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "    # Create an initial grid\n",
    "    grid_gdf = create_grid((minx, miny, maxx, maxy), max_cellsize)\n",
    "\n",
    "    # Subdivide grid elements based on density and complexity\n",
    "    subdivided_elements = subdivide_grid(grid_gdf, gdf, max_cellsize, max_complexity)\n",
    "\n",
    "    return gpd.GeoDataFrame(geometry=subdivided_elements)\n",
    "\n",
    "\n",
    "#  TODO: refactor this so old function mantains functionality for marine areas\n",
    "\n",
    "def split_gdf_by_grid(gdf: gpd.GeoDataFrame, grid_gdf: gpd.GeoDataFrame):\n",
    "    result = []\n",
    "    gdf[\"already_processed\"] = False\n",
    "    for geometry in grid_gdf.geometry:\n",
    "        candidates = get_matches(geometry, gdf)\n",
    "        subset = gdf.loc[candidates.index][~gdf[\"already_processed\"]]\n",
    "        gdf.loc[subset.index, \"already_processed\"] = True\n",
    "        if not subset.empty:\n",
    "            result.append(subset.drop(columns=[\"already_processed\"]).reset_index(drop=True).copy())\n",
    "    return result\n",
    "\n",
    "\n",
    "@background\n",
    "def spatial_join_chunk(df_large_chunk, df_small, pbar):\n",
    "    try:\n",
    "        bbox = df_large_chunk.total_bounds\n",
    "\n",
    "        candidates = get_matches(box(*bbox), df_small.geometry)\n",
    "        if len(candidates) > 0:\n",
    "            subset = df_small.loc[candidates.index].clip(box(*bbox))\n",
    "\n",
    "            result = (\n",
    "                gpd.overlay(df_large_chunk, subset).reset_index(drop=True)\n",
    "                .clip(subset.geometry)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            result.geometry = result.geometry.apply(repair_geometry)\n",
    "        else:\n",
    "            result = gpd.GeoDataFrame(columns=df_large_chunk.columns)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return gpd.GeoDataFrame()\n",
    "    finally:\n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "async def spatial_join(\n",
    "    geodataframe_a: gpd.GeoDataFrame, geodataframe_b: gpd.GeoDataFrame\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"Create spatial join between two GeoDataFrames.\"\"\"\n",
    "    # we build the spatial index for the larger GeoDataFrame\n",
    "    smaller_dim, larger_dim = arrange_dimensions(geodataframe_a, geodataframe_b)\n",
    "\n",
    "    logger.info(f\"Processing {len(larger_dim)} elements\")\n",
    "\n",
    "    grid = create_density_based_grid(larger_dim, max_cellsize=10, max_complexity=5000)\n",
    "\n",
    "    logger.info(f\"grid created with {len(grid)} cells\")\n",
    "\n",
    "    list_of_chunks = split_gdf_by_grid(larger_dim, grid)\n",
    "\n",
    "    logger.info(f\"grid split into {len(list_of_chunks)} chunks\")\n",
    "\n",
    "    with tqdm(total=len(list_of_chunks)) as pbar:  # we create a progress bar\n",
    "        new_df = await asyncio.gather(\n",
    "            *(spatial_join_chunk(chunk, smaller_dim, pbar) for chunk in list_of_chunks)\n",
    "        )\n",
    "\n",
    "    return gpd.GeoDataFrame(pd.concat(new_df, ignore_index=True), crs=smaller_dim.crs)\n",
    "\n",
    "\n",
    "@background\n",
    "def spatial_dissolve_chunk(geometry, gdf, pbar):\n",
    "    try:\n",
    "        logger.info(\"Processing chunk\")\n",
    "        candidates = get_matches(\n",
    "            geometry,\n",
    "            gdf.geometry,\n",
    "        )\n",
    "        subset = gdf.loc[candidates.index]\n",
    "\n",
    "        result = pd.concat(\n",
    "            subset.clip(geometry).pipe(split_by_year, year_col=\"STATUS_YR\"), ignore_index=True\n",
    "        ).copy()\n",
    "\n",
    "        data_chunk = [\n",
    "            (\n",
    "                result[result[\"year\"] <= 2010]\n",
    "                .reset_index()\n",
    "                .pipe(calculate_area, \"area\", None)\n",
    "                .drop(columns=[\"geometry\"])\n",
    "            )\n",
    "        ]\n",
    "        for year in range(2011, 2025):\n",
    "            data_chunk.append(\n",
    "                result[result[\"year\"] <= year]\n",
    "                .dissolve(\n",
    "                    by=[\"iso_3\"],\n",
    "                )\n",
    "                .assign(year=year)\n",
    "                .reset_index()\n",
    "                .pipe(calculate_area, \"area\", None)\n",
    "                .drop(columns=[\"geometry\"])\n",
    "            )\n",
    "\n",
    "        return pd.concat(data_chunk, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return gpd.GeoDataFrame()\n",
    "    finally:\n",
    "        pbar.update(1)\n",
    "\n",
    "async def process_grid(gdf):\n",
    "    grid_gdf = create_density_based_grid(gdf, max_cellsize=10, max_complexity=5000)\n",
    "    logger.info(f\"grid created with {grid_gdf.shape[0]} cells\")\n",
    "\n",
    "    with tqdm(total=grid_gdf.shape[0], desc=\"Processing grid elements\") as pbar:\n",
    "        jobs = [spatial_dissolve_chunk(geometry, gdf, pbar) for geometry in grid_gdf.geometry.values]\n",
    "        result = await asyncio.gather(*jobs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage stats - Mpas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the intermediate data from eez, in order to create a dataset that can be used as a land mask.\n",
    "The steps are:\n",
    "1. Load eez\n",
    "2. Spatial inner Join the eez dataset with the Mpas one\n",
    "3. Assign the location iso\n",
    "4. dissolve by location iso and cummulative year\n",
    "5. calculate the area for global regions and eez countries\n",
    "6. prepare the data to be ingested in strapi\n",
    "7. upload the data to strapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sofia/dev/skytruth-30x30/data/data/eez/processed/eez_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/eez/processed/preprocess\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpa/processed/mpa_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpa/processed/preprocess\n"
     ]
    }
   ],
   "source": [
    "pipe = \"mpa\"\n",
    "strapi_collection = \"\"\n",
    "\n",
    "pipe_dir_eez = FileConventionHandler(\"eez\")\n",
    "pipe_dir_mpas = FileConventionHandler(pipe)\n",
    "output_file = pipe_dir_mpas.get_processed_step_path(current_step).joinpath(\n",
    "    \"mpa_landmask_strapi.csv\"\n",
    ")\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir_eez, prev_step, mysettings)\n",
    "# Download the mpas file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir_mpas, prev_step, mysettings)\n",
    "\n",
    "# Load the data\n",
    "eez = gpd.read_file(pipe_dir_eez.get_step_fmt_file_path(prev_step, \"shp\")).pipe(clean_geometries)\n",
    "mpas = gpd.read_file(pipe_dir_mpas.get_step_fmt_file_path(prev_step, \"shp\")).pipe(clean_geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [08:15<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "eez_mpas_data_join = await spatial_join(eez, mpas.pipe(filter_by_exluding_propossed_mpas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WDPAID</th>\n",
       "      <th>WDPA_PID</th>\n",
       "      <th>PA_DEF</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESIG_ENG</th>\n",
       "      <th>IUCN_CAT</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>STATUS_YR</th>\n",
       "      <th>PARENT_ISO</th>\n",
       "      <th>GIS_M_AREA</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>GEONAME</th>\n",
       "      <th>MRGID</th>\n",
       "      <th>AREA_KM2</th>\n",
       "      <th>POL_TYPE</th>\n",
       "      <th>ISO_SOV1</th>\n",
       "      <th>ISO_SOV2</th>\n",
       "      <th>ISO_SOV3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555624810.0</td>\n",
       "      <td>555624810_D</td>\n",
       "      <td>1</td>\n",
       "      <td>Ross Sea Region Marine Protected Area</td>\n",
       "      <td>Marine Protected Area (CCAMLR)</td>\n",
       "      <td>Not Reported</td>\n",
       "      <td>Designated</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>ABNJ</td>\n",
       "      <td>326507.190744</td>\n",
       "      <td>POLYGON ((150 -62.5, 150.90909 -62.5, 151.8181...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High Seas</td>\n",
       "      <td>63203.0</td>\n",
       "      <td>212881389.0</td>\n",
       "      <td>High Seas</td>\n",
       "      <td>ABNJ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WDPAID     WDPA_PID PA_DEF                                   NAME  \\\n",
       "0  555624810.0  555624810_D      1  Ross Sea Region Marine Protected Area   \n",
       "\n",
       "                        DESIG_ENG      IUCN_CAT      STATUS  STATUS_YR  \\\n",
       "0  Marine Protected Area (CCAMLR)  Not Reported  Designated     2017.0   \n",
       "\n",
       "  PARENT_ISO     GIS_M_AREA  \\\n",
       "0       ABNJ  326507.190744   \n",
       "\n",
       "                                            geometry  index_right    GEONAME  \\\n",
       "0  POLYGON ((150 -62.5, 150.90909 -62.5, 151.8181...          0.0  High Seas   \n",
       "\n",
       "     MRGID     AREA_KM2   POL_TYPE ISO_SOV1 ISO_SOV2 ISO_SOV3  \n",
       "0  63203.0  212881389.0  High Seas     ABNJ     None     None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eez_mpas_data_join.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 17,697 records\n"
     ]
    }
   ],
   "source": [
    "# # To get an idea of the spatial join results\n",
    "# eez_mpas_data_join.pipe(add_location_iso).pipe(assign_iso3).to_file(\n",
    "#     pipe_dir_mpas.get_processed_step_path(current_step).joinpath(\"mpas_sjoin.shp\"), driver=\"ESRI Shapefile\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [03:23<00:00, 14.54s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [03:23<00:00,  4.58s/it]"
     ]
    }
   ],
   "source": [
    "final_data = await process_mpa_data(\n",
    "    eez_mpas_data_join.pipe(add_location_iso).pipe(assign_iso3),\n",
    "    range(2011, time.localtime().tm_year + 1),\n",
    "    [\"PA_DEF\", \"iso_3\"],\n",
    "    {\"protectedAreasCount\": \"sum\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>iso_3</th>\n",
       "      <th>area</th>\n",
       "      <th>protected_areas_count</th>\n",
       "      <th>oecms</th>\n",
       "      <th>pas</th>\n",
       "      <th>total_marine_area</th>\n",
       "      <th>protected_area</th>\n",
       "      <th>coverage</th>\n",
       "      <th>global_contribution</th>\n",
       "      <th>is_last_year</th>\n",
       "      <th>environment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>ABNJ</td>\n",
       "      <td>996236.125498</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>212881389.0</td>\n",
       "      <td>996236.13</td>\n",
       "      <td>0.467977</td>\n",
       "      <td>0.275966</td>\n",
       "      <td>False</td>\n",
       "      <td>marine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>AF</td>\n",
       "      <td>129790.939474</td>\n",
       "      <td>427.0</td>\n",
       "      <td>2.34192</td>\n",
       "      <td>97.65808</td>\n",
       "      <td>14878058.0</td>\n",
       "      <td>129790.94</td>\n",
       "      <td>0.872365</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>False</td>\n",
       "      <td>marine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year iso_3           area  protected_areas_count    oecms        pas  \\\n",
       "0  2010  ABNJ  996236.125498                   29.0  0.00000  100.00000   \n",
       "1  2010    AF  129790.939474                  427.0  2.34192   97.65808   \n",
       "\n",
       "   total_marine_area  protected_area  coverage  global_contribution  \\\n",
       "0        212881389.0       996236.13  0.467977             0.275966   \n",
       "1         14878058.0       129790.94  0.872365             0.035953   \n",
       "\n",
       "   is_last_year environment  \n",
       "0         False      marine  \n",
       "1         False      marine  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage = (\n",
    "    final_data.pipe(calculate_global_area, [\"year\", \"PA_DEF\"], {\"area\": \"sum\"}, \"iso_3\")\n",
    "    .pipe(separate_parent_iso, \"iso_3\")\n",
    "    .pipe(add_region_iso, \"iso_3\")\n",
    "    .replace(\n",
    "        {\n",
    "            \"iso_3\": {\n",
    "                \"ATA\": \"ABNJ\",\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "                \"GIB\": \"GBR\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .pipe(calculate_stats_cov, [\"year\", \"PA_DEF\"], \"iso_3\").astype({\"PA_DEF\": int})\n",
    "    .pipe(add_mpa_oecm_percentages)\n",
    "    .pipe(add_total_marine_area)\n",
    "    .pipe(coverage_stats2)\n",
    "    .pipe(calculate_coverage_percentage_pa)\n",
    "    .pipe(calculate_global_contribution)\n",
    "    .pipe(add_is_last_year)\n",
    "    .pipe(add_environment)\n",
    ")\n",
    "\n",
    "\n",
    "NewProtectedAreaExtentSchema(\n",
    "    coverage.pipe(\n",
    "        output,\n",
    "        \"iso_3\",\n",
    "        {},\n",
    "        {},\n",
    "        [\"area\", \"iso_3\", 'total_marine_area'],\n",
    "    )\n",
    ").to_csv(\n",
    "    output_file,\n",
    "    index=True,\n",
    ")\n",
    "coverage.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n"
     ]
    }
   ],
   "source": [
    "remote_path = 'vizzuality_processed_data/strapi_tables/mpa_coverage.csv'\n",
    "\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strapi_collection = \"protection-coverage-stat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<helpers.strapi.Strapi at 0x7fda8ddb8860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# strapi.deleteCollectionData(strapi_collection, list(range(1, 2300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strapi.importCollectionData(\n",
    "#     strapi_collection,\n",
    "#     output_file,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage stats - terrestrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sofia/dev/skytruth-30x30/data/data/mpa-terrestrial/processed/mpa-terrestrial_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpa-terrestrial/processed/preprocess\n",
      "/home/sofia/dev/skytruth-30x30/data/data/gadm/processed/gadm_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/gadm/processed/preprocess\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sofia/dev/skytruth-30x30/data/data/gadm/processed/preprocess')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = \"mpa-terrestrial\"\n",
    "step = \"preprocess\"\n",
    "strapi_collection_mpas = \"mpa-terrestrial\"\n",
    "\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "pipe_dir_gadm = FileConventionHandler(\"gadm\")\n",
    "\n",
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "output_file_sjoin = pipe_dir.get_processed_step_path(current_step).joinpath(\"tpa_sjoin.shp\")\n",
    "output_file_dissolve = pipe_dir.get_processed_step_path(current_step).joinpath(\"tpa_dissolve.csv\")\n",
    "output_file_tpas = pipe_dir.get_processed_step_path(current_step).joinpath(\"tpa_detail.csv\")\n",
    "\n",
    "# Download the protected atlas file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir, prev_step, mysettings)\n",
    "# Download the mpaatlas file \n",
    "download_and_unzip_if_needed(pipe_dir_gadm, prev_step, mysettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<geopandas.sindex.SpatialIndex at 0x7f706660eb40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Load the data\n",
    "# wdpa = gpd.read_file(pipe_dir.get_step_fmt_file_path(prev_step, \"gpkg\")).pipe(\n",
    "#     clean_geometries\n",
    "# )\n",
    "# gadm = gpd.read_file(pipe_dir_gadm.get_step_fmt_file_path(prev_step, \"shp\")).pipe(clean_geometries)\n",
    "\n",
    "# gadm.sindex\n",
    "# wdpa.sindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spatial join using overlay\n",
    "# wdpa_subset = wdpa[\n",
    "#     ~(\n",
    "#         (wdpa.bounds.minx < -181)\n",
    "#         | (wdpa.bounds.miny < -91)\n",
    "#         | (wdpa.bounds.maxx > 181)\n",
    "#         | (wdpa.bounds.maxy > 91)\n",
    "#     )\n",
    "# ].reset_index(drop=True)\n",
    "\n",
    "# sjoin_gdf = await spatial_join(wdpa_subset, gadm)\n",
    "# sjoin_gdf.rename(columns={\"GID_0\": \"iso_3\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WDPAID</th>\n",
       "      <th>WDPA_PID</th>\n",
       "      <th>PA_DEF</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESIG_ENG</th>\n",
       "      <th>IUCN_CAT</th>\n",
       "      <th>MARINE</th>\n",
       "      <th>GIS_AREA</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>STATUS_YR</th>\n",
       "      <th>PARENT_ISO</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>iso_3</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [WDPAID, WDPA_PID, PA_DEF, NAME, DESIG_ENG, IUCN_CAT, MARINE, GIS_AREA, STATUS, STATUS_YR, PARENT_ISO, COUNTRY, iso_3, area_km2, geometry]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # test that we have not produce duplicates\n",
    "# sjoin_gdf.loc[sjoin_gdf.duplicated(subset=[\"WDPA_PID\", \"iso_3\"], keep=False)].sort_values(\n",
    "#     \"WDPA_PID\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289352"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sjoin_gdf = filter_by_exluding_propossed_mpas(sjoin_gdf)\n",
    "# len(sjoin_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 289,352 records\n"
     ]
    }
   ],
   "source": [
    "# # Save the spatial join\n",
    "# sjoin_gdf.to_file(output_file_sjoin, driver=\"ESRI Shapefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjoin_gdf = gpd.read_file(output_file_sjoin)\n",
    "sjoin_gdf[\"STATUS_YR\"] = sjoin_gdf[\"STATUS_YR\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PA_DEF</th>\n",
       "      <th>iso_3</th>\n",
       "      <th>year</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>protected_areas_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2021</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2022</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2024</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2889 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "PA_DEF iso_3  year    1    0  protected_areas_count\n",
       "0        AFG  2010   10  0.0                   10.0\n",
       "1        AFG  2011   10  0.0                   10.0\n",
       "2        AFG  2012   10  0.0                   10.0\n",
       "3        AFG  2013   10  0.0                   10.0\n",
       "4        AFG  2014   10  0.0                   10.0\n",
       "...      ...   ...  ...  ...                    ...\n",
       "2884     ZWE  2020  229  0.0                  229.0\n",
       "2885     ZWE  2021  229  0.0                  229.0\n",
       "2886     ZWE  2022  229  0.0                  229.0\n",
       "2887     ZWE  2023  229  0.0                  229.0\n",
       "2888     ZWE  2024  229  0.0                  229.0\n",
       "\n",
       "[2889 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Calculate wdpa cumulative counts and pa and oecm percentages\n",
    "cumulative_counts = cumulative_pa_def_counts(sjoin_gdf)\n",
    "cumulative_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dissolve geometries to calculate the coverage\n",
    "# data = await process_grid(sjoin_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tpa = pd.concat(data, ignore_index=True).drop(columns=['STATUS_YR', 'index']).rename(columns={'area': 'protected_area'})\n",
    "# tpa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by 'iso_3' and 'year' and sum the 'area'\n",
    "# tpa_grouped = tpa.groupby(['iso_3', 'year'], as_index=False)['protected_area'].sum()\n",
    "# tpa_grouped.reset_index(drop=True, inplace=True)\n",
    "# tpa_grouped.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save to csv\n",
    "# tpa_grouped.to_csv(output_file_dissolve, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_3</th>\n",
       "      <th>year</th>\n",
       "      <th>protected_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2010</td>\n",
       "      <td>1078.918622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2011</td>\n",
       "      <td>1078.918622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2012</td>\n",
       "      <td>1078.918622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2013</td>\n",
       "      <td>1078.918622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2014</td>\n",
       "      <td>1078.918622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_3  year  protected_area\n",
       "0   AFG  2010     1078.918622\n",
       "1   AFG  2011     1078.918622\n",
       "2   AFG  2012     1078.918622\n",
       "3   AFG  2013     1078.918622\n",
       "4   AFG  2014     1078.918622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tpa_grouped = pd.read_csv(output_file_dissolve)\n",
    "tpa_grouped.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>iso_3</th>\n",
       "      <th>protected_area</th>\n",
       "      <th>protected_areas_count</th>\n",
       "      <th>oecms</th>\n",
       "      <th>pas</th>\n",
       "      <th>total_terrestrial_area</th>\n",
       "      <th>coverage</th>\n",
       "      <th>global_contribution</th>\n",
       "      <th>is_last_year</th>\n",
       "      <th>environment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>AF</td>\n",
       "      <td>3.636311e+06</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29993094.71</td>\n",
       "      <td>12.123827</td>\n",
       "      <td>2.694465</td>\n",
       "      <td>False</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>AS</td>\n",
       "      <td>2.051386e+06</td>\n",
       "      <td>24782.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31625555.58</td>\n",
       "      <td>6.486481</td>\n",
       "      <td>1.520053</td>\n",
       "      <td>False</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>AT</td>\n",
       "      <td>1.108333e+02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12088229.65</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>False</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>EU</td>\n",
       "      <td>4.306080e+06</td>\n",
       "      <td>116128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30037571.37</td>\n",
       "      <td>14.335645</td>\n",
       "      <td>3.190756</td>\n",
       "      <td>False</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.006295e+06</td>\n",
       "      <td>52176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19371151.92</td>\n",
       "      <td>10.357127</td>\n",
       "      <td>1.486642</td>\n",
       "      <td>False</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>2024</td>\n",
       "      <td>YEM</td>\n",
       "      <td>5.145397e+03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>453741.18</td>\n",
       "      <td>1.133994</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>True</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>2024</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>1.143850e+05</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1221327.52</td>\n",
       "      <td>9.365631</td>\n",
       "      <td>0.084758</td>\n",
       "      <td>True</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>2024</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>2.929805e+05</td>\n",
       "      <td>557.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>753990.33</td>\n",
       "      <td>38.857330</td>\n",
       "      <td>0.217095</td>\n",
       "      <td>True</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>2024</td>\n",
       "      <td>ZNC</td>\n",
       "      <td>2.779983e+00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3314.08</td>\n",
       "      <td>0.083884</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>True</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>2024</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>1.096232e+05</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>391234.88</td>\n",
       "      <td>28.019803</td>\n",
       "      <td>0.081230</td>\n",
       "      <td>True</td>\n",
       "      <td>terrestrial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2994 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year iso_3  protected_area  protected_areas_count  oecms    pas  \\\n",
       "0     2010    AF    3.636311e+06                 7272.0    0.0  100.0   \n",
       "1     2010    AS    2.051386e+06                24782.0    0.0  100.0   \n",
       "2     2010    AT    1.108333e+02                    2.0    0.0  100.0   \n",
       "3     2010    EU    4.306080e+06               116128.0    0.0  100.0   \n",
       "4     2010    NA    2.006295e+06                52176.0    0.0  100.0   \n",
       "...    ...   ...             ...                    ...    ...    ...   \n",
       "2989  2024   YEM    5.145397e+03                   15.0    0.0  100.0   \n",
       "2990  2024   ZAF    1.143850e+05                 1631.0    0.0  100.0   \n",
       "2991  2024   ZMB    2.929805e+05                  557.0    0.0  100.0   \n",
       "2992  2024   ZNC    2.779983e+00                    8.0    0.0  100.0   \n",
       "2993  2024   ZWE    1.096232e+05                  229.0    0.0  100.0   \n",
       "\n",
       "      total_terrestrial_area   coverage  global_contribution  is_last_year  \\\n",
       "0                29993094.71  12.123827             2.694465         False   \n",
       "1                31625555.58   6.486481             1.520053         False   \n",
       "2                12088229.65   0.000917             0.000082         False   \n",
       "3                30037571.37  14.335645             3.190756         False   \n",
       "4                19371151.92  10.357127             1.486642         False   \n",
       "...                      ...        ...                  ...           ...   \n",
       "2989               453741.18   1.133994             0.003813          True   \n",
       "2990              1221327.52   9.365631             0.084758          True   \n",
       "2991               753990.33  38.857330             0.217095          True   \n",
       "2992                 3314.08   0.083884             0.000002          True   \n",
       "2993               391234.88  28.019803             0.081230          True   \n",
       "\n",
       "      environment  \n",
       "0     terrestrial  \n",
       "1     terrestrial  \n",
       "2     terrestrial  \n",
       "3     terrestrial  \n",
       "4     terrestrial  \n",
       "...           ...  \n",
       "2989  terrestrial  \n",
       "2990  terrestrial  \n",
       "2991  terrestrial  \n",
       "2992  terrestrial  \n",
       "2993  terrestrial  \n",
       "\n",
       "[2994 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add pa and oecm counts to the coverage table\n",
    "coverage = (\n",
    "    pd.merge(tpa_grouped, cumulative_counts, on=['iso_3', 'year'], how='left')\n",
    "    .pipe(add_region_iso2, \"iso_3\")\n",
    "    .pipe(calculate_stats_cov_pa, [\"year\"], \"iso_3\")\n",
    "    .pipe(calculate_pa_def_percentages)\n",
    "    .pipe(add_total_terrestrial_area)\n",
    "    .pipe(calculate_coverage_percentage_pa)\n",
    "    .pipe(calculate_global_contribution)\n",
    "    .pipe(add_is_last_year)\n",
    "    .pipe(add_environment)\n",
    ")\n",
    "\n",
    "NewProtectedAreaExtentSchema(\n",
    "    coverage.pipe(\n",
    "        output2,\n",
    "        \"iso_3\",\n",
    "        {},\n",
    "        {},\n",
    "        [\"iso_3\", 'total_terrestrial_area'],\n",
    "    )\n",
    ").to_csv(\n",
    "    output_file_tpas,\n",
    "    index=True,\n",
    ")\n",
    "\n",
    "coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage stats - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = \"pa\"\n",
    "pipe_tpa = \"mpa-terrestrial\"\n",
    "pipe_mpa = \"mpa\"\n",
    "step = \"preprocess\"\n",
    "\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "pipe_dir_tpa = FileConventionHandler(pipe_tpa)\n",
    "pipe_dir_mpa = FileConventionHandler(pipe_mpa)\n",
    "\n",
    "input_path_tpas = pipe_dir_tpa.get_processed_step_path(current_step).joinpath(\"tpa_coverage.csv\")\n",
    "input_path_mpas = pipe_dir_mpa.get_processed_step_path(current_step).joinpath(\"mpa_coverage.csv\")\n",
    "\n",
    "output_file = pipe_dir.get_processed_step_path(current_step).joinpath(\"protection_coverage_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpa = pd.read_csv(input_path_tpas)\n",
    "mpa = pd.read_csv(input_path_mpas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>protected_area</th>\n",
       "      <th>protected_areas_count</th>\n",
       "      <th>oecms</th>\n",
       "      <th>pas</th>\n",
       "      <th>coverage</th>\n",
       "      <th>global_contribution</th>\n",
       "      <th>is_last_year</th>\n",
       "      <th>environment</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.636311e+06</td>\n",
       "      <td>7272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.123827</td>\n",
       "      <td>2.694465</td>\n",
       "      <td>False</td>\n",
       "      <td>terrestrial</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year  protected_area  protected_areas_count  oecms    pas   coverage  \\\n",
       "1   1  2010    3.636311e+06                   7272    0.0  100.0  12.123827   \n",
       "\n",
       "   global_contribution  is_last_year  environment  location  \n",
       "1             2.694465         False  terrestrial         3  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the two dataframes\n",
    "final_data = pd.concat([tpa, mpa], ignore_index=True)\n",
    "final_data.index = range(1, len(final_data) + 1)\n",
    "final_data['id'] = final_data.index\n",
    "final_data[final_data['id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewProtectedAreaExtentSchema(final_data).to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mpa atlas - country stats Fully or highly protected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the intermediate data from eez, in order to create a dataset that can be used as a land mask.\n",
    "The steps are:\n",
    "1. Load eez\n",
    "2. Spatial inner Join the eez dataset with the Mpaatlas one\n",
    "3. iso assign using the sovereign one provided by mpaatlas\n",
    "4. dissolve by location\n",
    "5. calculate the area for global regions and eez countries ussing mollwide projection\n",
    "6. prepare the data to be ingested in strapi\n",
    "7. upload the data to strapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sofia/dev/skytruth-30x30/data/data/eez/processed/eez_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/eez/processed/preprocess\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpaatlas/processed/mpaatlas_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpaatlas/processed/preprocess\n"
     ]
    }
   ],
   "source": [
    "pipe = \"mpaatlas\"\n",
    "strapi_collection = \"mpaa-protection-level-stat\"\n",
    "\n",
    "pipe_dir_eez = FileConventionHandler(\"eez\")\n",
    "pipe_dir_mpaatlas = FileConventionHandler(pipe)\n",
    "output_file = pipe_dir_mpaatlas.get_processed_step_path(current_step).joinpath(\n",
    "    \"mpaatlas_protection_level.csv\"\n",
    ")\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir_eez, prev_step, mysettings)\n",
    "# Download the mpas file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir_mpaatlas, prev_step, mysettings)\n",
    "\n",
    "# Load the data\n",
    "eez = gpd.read_file(pipe_dir_eez.get_step_fmt_file_path(prev_step, \"shp\")).pipe(clean_geometries)\n",
    "mpaatlas_intermediate = gpd.read_file(\n",
    "    pipe_dir_mpaatlas.get_step_fmt_file_path(prev_step, \"shp\")\n",
    ").pipe(clean_geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:29<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:29<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    }
   ],
   "source": [
    "eez_mpaatlas_data_join = await spatial_join(\n",
    "    eez, mpaatlas_intermediate.pipe(mpaatlas_filter_stablishment)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get an idea of the spatial join results\n",
    "# eez_mpaatlas_data_join.to_file(\n",
    "#     pipe_dir_mpaatlas.get_processed_step_path(current_step).joinpath(\"mpaatlas_sjoin.shp\"),\n",
    "#     driver=\"ESRI Shapefile\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 54 records\n"
     ]
    }
   ],
   "source": [
    "eez_mpaatlas_data_join.dissolve(by=[\"protecti_1\", \"location_i\"], aggfunc={\"name\": \"count\"}).reset_index().to_file(\n",
    "pipe_dir_mpaatlas.get_processed_step_path(current_step).joinpath(\"mpaatlas_sjoin_dissolved.shp\"),\n",
    "driver=\"ESRI Shapefile\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    eez_mpaatlas_data_join.rename(columns={\"location_i\": \"iso_3\"})\n",
    "    .pipe(process_mpaatlas_data)  \n",
    "    .pipe(calculate_global_area, gby_col=[\"protecti_1\"], iso_column=\"iso_3\")\n",
    "    .pipe(separate_parent_iso)\n",
    "    .replace(\n",
    "        {\n",
    "            \"location_i\": {\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .pipe(add_region_iso, iso_column=\"iso_3\")\n",
    "    .pipe(calculate_stats, gby_col=[\"protecti_1\"], iso_column=\"iso_3\")\n",
    "    .query('protecti_1 != \"less protected or unknown\"')\n",
    "    .pipe(fix_monaco, iso_column=\"iso_3\", area_column=\"area_km2\")\n",
    "    .pipe(add_total_marine_area)\n",
    "    .pipe(calculate_coverage_percentage_mpatlas)\n",
    "    .pipe(\n",
    "        output,\n",
    "        iso_column=\"iso_3\",\n",
    "        rep_d={\n",
    "            \"protecti_1\": {\n",
    "                \"fully or highly protected\": 1,\n",
    "            }\n",
    "        },\n",
    "        rename={\"protecti_1\": \"mpaa_protection_level\", \"area_km2\": \"area\"},\n",
    "        drop_cols=[\"total_marine_area\", \"iso_3\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "NewProtectionLevelSchema(result[~result.location.isna()].assign(year=2024)).to_csv(\n",
    "    output_file, index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n"
     ]
    }
   ],
   "source": [
    "remote_path = 'vizzuality_processed_data/strapi_tables/mpaatlas_protection_level.csv'\n",
    "\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strapi_collection = \"mpaa-protection-level-stat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<helpers.strapi.Strapi at 0x7fda8ddb8860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# strapi.deleteCollectionData(strapi_collection, list(range(1, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strapi.importCollectionData(\n",
    "#     strapi_collection,\n",
    "#     output_file,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protected seas  - fishing protection level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n"
     ]
    }
   ],
   "source": [
    "pipe = \"protectedseas\"\n",
    "strapi_collection = \"fishing-protection-level-stat\"\n",
    "\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "input_file = pipe_dir.get_processed_step_path(prev_step).joinpath(\"protectedseas_stats.xlsx\")\n",
    "output_file = pipe_dir.get_processed_step_path(current_step).joinpath(\"lfp.csv\")\n",
    "\n",
    "# Download the protected seas file && unzip it\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=\"vizzuality_processed_data/protectedseas/preprocess/protectedseas_stats.xlsx\",\n",
    "    file=input_file,\n",
    "    operation=\"r\",\n",
    ")\n",
    "\n",
    "# Load the data\n",
    "protectedseas_intermediate = pd.read_excel(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_ter</th>\n",
       "      <th>iso_sov</th>\n",
       "      <th>includes_multi_jurisdictional_areas</th>\n",
       "      <th>lfp</th>\n",
       "      <th>area_sqkm</th>\n",
       "      <th>total_area</th>\n",
       "      <th>pct_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESP</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>142.973010</td>\n",
       "      <td>1011023.776</td>\n",
       "      <td>0.014141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESP</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1639.682076</td>\n",
       "      <td>1011023.776</td>\n",
       "      <td>0.162180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESP</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>214532.849800</td>\n",
       "      <td>1011023.776</td>\n",
       "      <td>21.219367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESP</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>15064.132770</td>\n",
       "      <td>1011023.776</td>\n",
       "      <td>1.489988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESP</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>779644.138800</td>\n",
       "      <td>1011023.776</td>\n",
       "      <td>77.114323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iso_ter iso_sov  includes_multi_jurisdictional_areas  lfp      area_sqkm  \\\n",
       "320     NaN     ESP                                 True    5     142.973010   \n",
       "321     NaN     ESP                                 True    4    1639.682076   \n",
       "322     NaN     ESP                                 True    3  214532.849800   \n",
       "323     NaN     ESP                                 True    2   15064.132770   \n",
       "324     NaN     ESP                                 True    1  779644.138800   \n",
       "\n",
       "      total_area  pct_total  \n",
       "320  1011023.776   0.014141  \n",
       "321  1011023.776   0.162180  \n",
       "322  1011023.776  21.219367  \n",
       "323  1011023.776   1.489988  \n",
       "324  1011023.776  77.114323  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protectedseas_intermediate[\n",
    "    (\n",
    "        protectedseas_intermediate.iso_ter.isna()\n",
    "        & protectedseas_intermediate.includes_multi_jurisdictional_areas.eq(True)\n",
    "    )\n",
    "    | (\n",
    "        protectedseas_intermediate.iso_ter.isna()\n",
    "        & protectedseas_intermediate.includes_multi_jurisdictional_areas.eq(False)\n",
    "        & ~protectedseas_intermediate.iso_sov.isin(\n",
    "            protectedseas_intermediate[\n",
    "                protectedseas_intermediate.includes_multi_jurisdictional_areas.eq(True)\n",
    "            ].iso_sov.unique()\n",
    "        )\n",
    "    )\n",
    "][protectedseas_intermediate.iso_sov.eq(\"ESP\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = (\n",
    "    protectedseas_intermediate[\n",
    "        (\n",
    "            protectedseas_intermediate.iso_ter.isna()\n",
    "            & protectedseas_intermediate.includes_multi_jurisdictional_areas.eq(True)\n",
    "        )\n",
    "        | (\n",
    "            protectedseas_intermediate.iso_ter.isna()\n",
    "            & protectedseas_intermediate.includes_multi_jurisdictional_areas.eq(False)\n",
    "            & ~protectedseas_intermediate.iso_sov.isin(\n",
    "                protectedseas_intermediate[\n",
    "                    protectedseas_intermediate.includes_multi_jurisdictional_areas.eq(True)\n",
    "                ].iso_sov.unique()\n",
    "            )\n",
    "        )\n",
    "    ].replace(\n",
    "        {\n",
    "            \"lfp\": {\n",
    "                5: \"highly\",\n",
    "                4: \"highly\",\n",
    "                3: \"moderately\",\n",
    "                2: \"less\",\n",
    "                1: \"less\",\n",
    "            },\n",
    "        }\n",
    "    ).groupby([\"iso_sov\", \"lfp\"]).agg({\"area_sqkm\": \"sum\", \"total_area\": \"max\"}).reset_index()\n",
    "    .pipe(\n",
    "        calculate_global_area,\n",
    "        gby_col=[\"lfp\"],\n",
    "        iso_column=\"iso_sov\",\n",
    "        agg_ops={\"area_sqkm\": \"sum\", \"total_area\": \"sum\"},\n",
    "    )\n",
    "    .pipe(add_region_iso, iso_column=\"iso_sov\")\n",
    "    .pipe(\n",
    "        calculate_stats,\n",
    "        gby_col=[\"lfp\"],\n",
    "        ops={\"area_sqkm\": \"sum\", \"total_area\": \"sum\"},\n",
    "        iso_column=\"iso_sov\",\n",
    "    )\n",
    "    .pipe(lambda x: x.assign(pct=round((x.area_sqkm / x.total_area)*100, 2)))\n",
    "    .pipe(\n",
    "        output,\n",
    "        iso_column=\"iso_sov\",\n",
    "        rep_d={\n",
    "            \"lfp\": {\n",
    "                \"highly\": 1,\n",
    "                \"moderately\": 2,\n",
    "                \"less\": 3,\n",
    "            }\n",
    "        },\n",
    "        rename={\"lfp\": \"fishing_protection_level\", \"area_sqkm\": \"area\"},\n",
    "        drop_cols=[\"iso_sov\", \"total_area\"],\n",
    "    )\n",
    ")\n",
    "FPLSchema(final[final.location.notna()]).to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n"
     ]
    }
   ],
   "source": [
    "remote_path = 'vizzuality_processed_data/strapi_tables/lfp.csv'\n",
    "\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strapi.deleteCollectionData(strapi_collection, list(range(1, 500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strapi.importCollectionData(\n",
    "#     strapi_collection,\n",
    "#     output_file,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1- lower case the columns   \n",
    "2- separate location that its regime is in dispute or on join regime  \n",
    "3- calcualte area for mpaatlas data  \n",
    "4- rename columns for merge  \n",
    "5- merge maaatlas and mpa data identifying the source  \n",
    "6- identify child resources and set them as childs  \n",
    "7- calculate bbox  \n",
    "8- set child resources  \n",
    "9- prepare output for batch export  \n",
    "10- upload data to strapi  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country mpas detail table data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1- lower case the columns   \n",
    "2- separate location that its regime is in dispute or on join regime  \n",
    "3- calcualte area for mpaatlas data  \n",
    "4- rename columns for merge  \n",
    "5- merge maaatlas and mpa data identifying the source  \n",
    "6- identify child resources and set them as childs  \n",
    "7- calculate bbox  \n",
    "8- set child resources  \n",
    "9- prepare output for batch export  \n",
    "10- upload data to strapi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sofia/dev/skytruth-30x30/data/data/mpa/processed/mpa_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpa/processed/preprocess\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpaatlas/processed/mpaatlas_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpaatlas/processed/preprocess\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sofia/dev/skytruth-30x30/data/data/mpaatlas/processed/preprocess')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = \"mpa\"\n",
    "strapi_collection_mpas = \"mpa\"\n",
    "\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "pipe_dir_mpaatlas = FileConventionHandler(\"mpaatlas\")\n",
    "output_file_mpas = pipe_dir.get_processed_step_path(current_step).joinpath(\"mpa_detail.csv\")\n",
    "\n",
    "# Download the protected atlas file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir, prev_step, mysettings)\n",
    "# Download the mpaatlas file \n",
    "download_and_unzip_if_needed(pipe_dir_mpaatlas, prev_step, mysettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "mpa_intermediate = gpd.read_file(pipe_dir.get_step_fmt_file_path(prev_step, \"shp\")).pipe(\n",
    "    clean_geometries\n",
    ")\n",
    "mpaatlas_intermediate = gpd.read_file(\n",
    "    pipe_dir_mpaatlas.get_step_fmt_file_path(prev_step, \"shp\")\n",
    ").pipe(clean_geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_table = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            (\n",
    "                mpa_intermediate.pipe(columns_to_lower)\n",
    "                .pipe(separate_parent_iso, iso_column=\"parent_iso\")\n",
    "                .pipe(change_ata_to_abnj)\n",
    "                .rename(\n",
    "                    columns={\n",
    "                        \"parent_iso\": \"iso\",\n",
    "                        \"status_yr\": \"year\",\n",
    "                        \"gis_m_area\": \"area_km2\",\n",
    "                    }\n",
    "                ).drop(columns=['status'])\n",
    "            ).assign(source=\"protected_planet\"),\n",
    "            (\n",
    "                mpaatlas_intermediate.pipe(calculate_area)\n",
    "                .pipe(extract_wdpaid_mpaatlas)\n",
    "                .pipe(separate_parent_iso, iso_column=\"location_i\")\n",
    "                .rename(\n",
    "                    columns={\n",
    "                        \"location_i\": \"iso\",\n",
    "                        \"wdpa_id\": \"wdpa_pid\",\n",
    "                        \"designatio\": \"desig_eng\",\n",
    "                    }\n",
    "                )\n",
    "            ).assign(source=\"mpaatlas\"\n",
    "            ).astype({\"mpa_zone_i\": \"Int64\"}),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .replace(\n",
    "        {\n",
    "            \"iso\": {\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .sort_values(by=[\"wdpa_pid\", \"wdpa_pid\", \"source\"], ascending=[True, True, False])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to be run if things change a lot in the future\n",
    "# iucn_cat = pd.DataFrame(\n",
    "#     {\"slug\": init_table.iucn_cat.dropna().unique(), \"name\": init_table.iucn_cat.dropna().unique()},\n",
    "#     index=pd.Index(np.arange(1, len(init_table.iucn_cat.dropna().unique()) + 1)),\n",
    "# )\n",
    "# iucn_cat.to_csv(pipe_dir.get_processed_step_path(current_step).joinpath(\"iucn_categories.csv\"), index=True)\n",
    "\n",
    "iucn_cat = pd.read_csv(\n",
    "    pipe_dir.get_processed_step_path(current_step).joinpath(\"iucn_categories.csv\"), index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpa_table = (\n",
    "    init_table.pipe(add_bbox, \"bbox\")\n",
    "    .pipe(define_is_child)\n",
    "    .pipe(set_child_id)\n",
    "    .sort_values(by=[\"wdpaid\", \"is_child\"], ascending=[True, True])\n",
    "    .reset_index(drop=True)\n",
    "    .pipe(add_total_marine_area)\n",
    "    .pipe(calculate_coverage_percentage_pa)\n",
    "    .pipe(add_environment)\n",
    "    .pipe(\n",
    "        output,\n",
    "        iso_column=\"iso\",\n",
    "        rep_d={\n",
    "            \"status\": {\n",
    "                \"Adopted\": 4,\n",
    "                \"implemented\": 6,\n",
    "                \"Established\": 6,\n",
    "                \"Designated\": 5,\n",
    "                \"Proposed\": 3,\n",
    "                \"Inscribed\": 3,\n",
    "                \"unknown\": 1,\n",
    "            },\n",
    "            \"pa_def\": {\"0\": 2, \"1\": 1},\n",
    "            \"year\": {0: pd.NA},\n",
    "            \"iucn_cat\": dict(\n",
    "                iucn_cat[[\"slug\"]]\n",
    "                .reset_index(drop=False)\n",
    "                .iloc[:, [1, 0]]\n",
    "                .to_dict(orient=\"tight\")[\"data\"]\n",
    "            ),\n",
    "            \"source\": {\"protected_planet\": 3, \"mpaatlas\": 1},\n",
    "            \"protection\": {\n",
    "                \"full\": 3,\n",
    "                \"light\": 4,\n",
    "                \"incompatible\": 5,\n",
    "                \"high\": 6,\n",
    "                \"minimal\": 7,\n",
    "                \"unknown\": 8,\n",
    "                \"unknown/to be determined\": 8,\n",
    "            },\n",
    "            \"establishm\": {\n",
    "                \"actively managed\": 4,\n",
    "                \"implemented\": 6,\n",
    "                \"designated\": 5,\n",
    "                \"Designated\": 5,\n",
    "                \"proposed or committed\": 3,\n",
    "                \"Proposed\": 3,\n",
    "                \"Inscribed\": 3,\n",
    "                \"Established\": 5,\n",
    "                \"Adopted\": 5,\n",
    "                \"unknown\": 1,\n",
    "            },\n",
    "        },\n",
    "        rename={\n",
    "            \"pa_def\": \"protection_status\",\n",
    "            \"area_km2\": \"area\",\n",
    "            \"iucn_cat\": \"pa_iucn_category\",\n",
    "            \"desig_eng\": \"designation\",\n",
    "            \"protection\": \"mpaa_protection_level\",\n",
    "            \"establishm\": \"mpaa_establishment_stage\",\n",
    "            \"source\": \"data_source\",\n",
    "        },\n",
    "        drop_cols=[\"geometry\", \"protecti_1\",\"mpa_zone_i\", \"iso\", \"total_marine_area\"]\n",
    "    )\n",
    "    .pipe(add_child_parent_relationship)\n",
    "    .astype(\n",
    "        {\n",
    "            \"year\": \"Int32\",\n",
    "            \"pa_iucn_category\": \"Int64\",\n",
    "            \"protection_status\": \"Int64\",\n",
    "        }\n",
    "    )\n",
    "    .query(\"coverage <= 100\") \n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate and save\n",
    "PAsSchema(mpa_table[mpa_table.location.notna()]).to_csv(output_file_mpas, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo investigate the issue with area as null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_export(\n",
    "#     mpa_table[mpa_table.area.notna()],\n",
    "#     5000,\n",
    "#     PAsSchema,\n",
    "#     pipe_dir.get_processed_step_path(current_step),\n",
    "#     \"mpa_detail\",\n",
    "#     format=\"json\",\n",
    "#     strapi_colection=strapi_collection_mpas,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code is to be able to identify groups that has wdpa_pid so in the future if needed we could combine the group geometries to generate a wdpa coverage geometry\n",
    "# init_table[\n",
    "#     (\n",
    "#         init_table.sort_values(by=[\"wdpaid\", \"source\"], ascending=[True, False])\n",
    "#         .groupby(\"wdpaid\")\n",
    "#         .transform(\"size\")\n",
    "#         .gt(1)\n",
    "#     )\n",
    "#     & (init_table.wdpa_pid.str.extract(r\"([A-Za-z]+)\", expand=False).notna())\n",
    "# ].groupby(\"wdpaid\")\n",
    "# .geometry.apply(lambda x: x.union_all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload data to strapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<helpers.strapi.Strapi at 0x7fda8ddb8860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# strapi.deleteCollectionData(\"mpa\", list(range(1, 20914)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, 4):\n",
    "#     strapi.importCollectionData(\n",
    "#         strapi_collection_mpas,\n",
    "#         mpa_folder.joinpath(f\"mpa_detail_{i}.csv\"),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country pas - detail table data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- lower case the columns   \n",
    "2- separate location that its regime is in dispute or on join regime \n",
    "3- remove ATA and ABNJ because Protected planet doesn't include stats for ATA and ABNJ is marine \n",
    "4- rename columns for merge   \n",
    "5- identify child resources and set them as childs  \n",
    "6- calculate bbox  \n",
    "7- set child resources  \n",
    "8- prepare output for batch export  \n",
    "9- upload data to strapi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sofia/dev/skytruth-30x30/data/data/mpa-terrestrial/processed/mpa-terrestrial_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/mpa-terrestrial/processed/preprocess\n",
      "/home/sofia/dev/skytruth-30x30/data/data/gadm/processed/gadm_preprocess.zip\n",
      "/home/sofia/dev/skytruth-30x30/data/data/gadm/processed/preprocess\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sofia/dev/skytruth-30x30/data/data/gadm/processed/preprocess')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = \"mpa-terrestrial\"\n",
    "strapi_collection_mpas = \"mpa-terrestrial\"\n",
    "\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "pipe_dir_gadm = FileConventionHandler(\"gadm\")\n",
    "output_file_tpas = pipe_dir.get_processed_step_path(current_step).joinpath(\"tpa_detail.csv\")\n",
    "\n",
    "# Download the protected atlas file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir, prev_step, mysettings)\n",
    "# Download the mpaatlas file \n",
    "download_and_unzip_if_needed(pipe_dir_gadm, prev_step, mysettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpa_intermediate = gpd.read_file(pipe_dir.get_step_fmt_file_path(prev_step, \"gpkg\")).pipe(\n",
    "    clean_geometries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iucn_cat = pd.read_csv(\n",
    "    pipe_dir.get_processed_step_path(current_step).joinpath(\"iucn_categories.csv\"), index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_table = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            (\n",
    "                tpa_intermediate.pipe(columns_to_lower)\n",
    "                .pipe(separate_parent_iso, iso_column=\"parent_iso\")\n",
    "                .query(\"parent_iso != 'ATA' and parent_iso != 'ABNJ'\")\n",
    "                .rename(\n",
    "                    columns={\n",
    "                        \"parent_iso\": \"iso\",\n",
    "                        \"status_yr\": \"year\",\n",
    "                        \"gis_area\": \"protected_area\",\n",
    "                    }\n",
    "                ).drop(columns=['status'])\n",
    "            ).assign(source=\"protected_planet\"),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .replace(\n",
    "        {\n",
    "            \"iso\": {\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .sort_values(by=[\"wdpa_pid\", \"wdpa_pid\", \"source\"], ascending=[True, True, False])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3510708/3364924951.py:202: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(rep_d)\n"
     ]
    }
   ],
   "source": [
    "tpa_table = (\n",
    "    init_table.pipe(add_bbox, \"bbox\")\n",
    "    .pipe(define_is_child)\n",
    "    .pipe(set_child_id_pa)\n",
    "    .sort_values(by=[\"wdpaid\", \"is_child\"], ascending=[True, True])\n",
    "    .reset_index(drop=True)\n",
    "    .pipe(add_total_terrestrial_area)\n",
    "    .pipe(calculate_coverage_percentage_pa)\n",
    "    .pipe(add_environment)\n",
    "    .pipe(\n",
    "        output2,\n",
    "        iso_column=\"iso\",\n",
    "        rep_d={\n",
    "            \"pa_def\": {\"0\": 2, \"1\": 1},\n",
    "            \"year\": {0: pd.NA},\n",
    "            \"iucn_cat\": dict(\n",
    "                iucn_cat[[\"slug\"]]\n",
    "                .reset_index(drop=False)\n",
    "                .iloc[:, [1, 0]]\n",
    "                .to_dict(orient=\"tight\")[\"data\"]\n",
    "            ),\n",
    "            \"source\": {\"protected_planet\": 3},\n",
    "        },\n",
    "        rename={\n",
    "            \"pa_def\": \"protection_status\",\n",
    "            \"protected_area\": \"area\",\n",
    "            \"iucn_cat\": \"pa_iucn_category\",\n",
    "            \"desig_eng\": \"designation\",\n",
    "            \"source\": \"data_source\",\n",
    "        },\n",
    "        drop_cols=[\"geometry\", \"iso\", \"marine\", \"total_terrestrial_area\"]\n",
    "    )\n",
    "    .pipe(add_child_parent_relationship)\n",
    "    .astype(\n",
    "        {\n",
    "            \"year\": \"Int32\",\n",
    "            \"pa_iucn_category\": \"Int64\",\n",
    "            \"protection_status\": \"Int64\",\n",
    "        }\n",
    "    )\n",
    "    .query(\"coverage <= 100\") \n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add col mpaa_protection_level and mpa_establishment_stage to the table to validate it\n",
    "tpa_table['mpaa_protection_level'] = np.nan\n",
    "tpa_table['mpaa_establishment_stage'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate and save\n",
    "PAsSchema(tpa_table[tpa_table.location.notna()]).to_csv(output_file_tpas, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_export(\n",
    "#     mpa_table[mpa_table.area.notna()],\n",
    "#     5000,\n",
    "#     PAsSchema,\n",
    "#     pipe_dir.get_processed_step_path(current_step),\n",
    "#     \"mpa_detail\",\n",
    "#     format=\"json\",\n",
    "#     strapi_colection=strapi_collection_mpas,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code is to be able to identify groups that has wdpa_pid so in the future if needed we could combine the group geometries to generate a wdpa coverage geometry\n",
    "# init_table[\n",
    "#     (\n",
    "#         init_table.sort_values(by=[\"wdpaid\", \"source\"], ascending=[True, False])\n",
    "#         .groupby(\"wdpaid\")\n",
    "#         .transform(\"size\")\n",
    "#         .gt(1)\n",
    "#     )\n",
    "#     & (init_table.wdpa_pid.str.extract(r\"([A-Za-z]+)\", expand=False).notna())\n",
    "# ].groupby(\"wdpaid\")\n",
    "# .geometry.apply(lambda x: x.union_all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<helpers.strapi.Strapi at 0x7fda8ddb8860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# strapi.deleteCollectionData(\"mpa\", list(range(1, 20914)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, 4):\n",
    "#     strapi.importCollectionData(\n",
    "#         strapi_collection_mpas,\n",
    "#         mpa_folder.joinpath(f\"mpa_detail_{i}.csv\"),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country marine and terrestrial - Detail table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mar = \"mpa\"\n",
    "pipe_ter = \"mpa-terrestrial\"\n",
    "pipe_pa = \"pa\"\n",
    "step = \"preprocess\"\n",
    "\n",
    "\n",
    "pipe_dir_mar = FileConventionHandler(pipe_mar)\n",
    "pipe_dir_ter = FileConventionHandler(pipe_ter)\n",
    "pipe_dir_pa = FileConventionHandler(pipe_pa)\n",
    "\n",
    "input_path_mar = pipe_dir_mar.get_processed_step_path(current_step).joinpath(\"mpa_detail.csv\")\n",
    "input_path_ter = pipe_dir_ter.get_processed_step_path(current_step).joinpath(\"tpa_detail.csv\")\n",
    "output_file_pa = pipe_dir_pa.get_processed_step_path(current_step).joinpath(\"pa_detail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpa_table = pd.read_csv(input_path_mar)\n",
    "tpa_table = pd.read_csv(input_path_ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wdpaid</th>\n",
       "      <th>wdpa_pid</th>\n",
       "      <th>protection_status</th>\n",
       "      <th>name</th>\n",
       "      <th>designation</th>\n",
       "      <th>pa_iucn_category</th>\n",
       "      <th>year</th>\n",
       "      <th>area</th>\n",
       "      <th>data_source</th>\n",
       "      <th>...</th>\n",
       "      <th>coverage</th>\n",
       "      <th>environment</th>\n",
       "      <th>location</th>\n",
       "      <th>children</th>\n",
       "      <th>protected_area</th>\n",
       "      <th>protected_areas_count</th>\n",
       "      <th>oecms</th>\n",
       "      <th>pas</th>\n",
       "      <th>global_contribution</th>\n",
       "      <th>is_last_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Diamond Reef and Salt Fish Tail Reef</td>\n",
       "      <td>Marine Reserve</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>14.636135</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>marine</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Palaster Reef</td>\n",
       "      <td>Marine Reserve</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>3.845623</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>marine</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  wdpaid wdpa_pid  protection_status  \\\n",
       "id                                           \n",
       "1    1     1.0        1                1.0   \n",
       "2    2     2.0        2                1.0   \n",
       "\n",
       "                                    name     designation  pa_iucn_category  \\\n",
       "id                                                                           \n",
       "1   Diamond Reef and Salt Fish Tail Reef  Marine Reserve               1.0   \n",
       "2                          Palaster Reef  Marine Reserve               1.0   \n",
       "\n",
       "      year       area  data_source  ...  coverage  environment  location  \\\n",
       "id                                  ...                                    \n",
       "1   1973.0  14.636135          3.0  ...  0.013119       marine        15   \n",
       "2   1973.0   3.845623          3.0  ...  0.003447       marine        15   \n",
       "\n",
       "   children protected_area protected_areas_count  oecms pas  \\\n",
       "id                                                            \n",
       "1       NaN            NaN                   NaN    NaN NaN   \n",
       "2       NaN            NaN                   NaN    NaN NaN   \n",
       "\n",
       "    global_contribution is_last_year  \n",
       "id                                    \n",
       "1                   NaN          NaN  \n",
       "2                   NaN          NaN  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create final table with all the data\n",
    "final_table = pd.concat([mpa_table, tpa_table])\n",
    "final_table.index = range(1, len(final_table) + 1)\n",
    "final_table.index.name = 'id'\n",
    "final_table.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAsSchema(final_table[final_table.location.notna()]).to_csv(output_file_pa, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n"
     ]
    }
   ],
   "source": [
    "remote_path = 'vizzuality_processed_data/strapi_tables/pa.csv'\n",
    "\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=output_file_pas,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mar = \"mpa\"\n",
    "pipe_ter = \"mpa-terrestrial\"\n",
    "step = \"preprocess\"\n",
    "\n",
    "\n",
    "pipe_dir_mar = FileConventionHandler(pipe_mar)\n",
    "pipe_dir_ter = FileConventionHandler(pipe_ter)\n",
    "\n",
    "input_path_mar = pipe_dir_mar.get_processed_step_path(current_step).joinpath(\"mpa_detail.csv\")\n",
    "input_path_ter = pipe_dir_ter.get_processed_step_path(current_step).joinpath(\"tpa_detail.csv\")\n",
    "output_file_pa = pipe_dir_ter.get_processed_step_path(current_step).joinpath(\"pa_detail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter = pd.read_csv(input_path_ter)\n",
    "mar = pd.read_csv(input_path_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'protected_area', 'protected_areas_count', 'oecms', 'pas',\n",
       "       'coverage', 'global_contribution', 'is_last_year', 'environment',\n",
       "       'location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'wdpaid', 'wdpa_pid', 'protection_status', 'name', 'designation',\n",
       "       'pa_iucn_category', 'year', 'area', 'data_source',\n",
       "       'mpaa_establishment_stage', 'mpaa_protection_level', 'bbox', 'is_child',\n",
       "       'child_id', 'coverage', 'environment', 'location', 'children'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location    0\n",
       "code        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_code.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location code\n",
       "6         7  NaN"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show rows with null values in locations_code\n",
    "locations_code[locations_code.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = (\n",
    "    final_data.pipe(calculate_global_area, [\"year\", \"PA_DEF\"], {\"area\": \"sum\"}, \"iso_3\")\n",
    "    .pipe(separate_parent_iso, \"iso_3\")\n",
    "    .pipe(add_region_iso, \"iso_3\")\n",
    "    .replace(\n",
    "        {\n",
    "            \"iso_3\": {\n",
    "                \"ATA\": \"ABNJ\",\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "                \"GIB\": \"GBR\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .pipe(calculate_stats_cov, [\"year\", \"PA_DEF\"], \"iso_3\").astype({\"PA_DEF\": int})\n",
    "    .pipe(add_pa_oecm_percentages)\n",
    "    .pipe(add_total_marine_area)\n",
    "    .pipe(coverage_stats2)\n",
    "    .pipe(calculate_coverage_percentage_mpa)\n",
    "    .pipe(calculate_global_contribution)\n",
    "    .pipe(add_is_last_year)\n",
    "    .pipe(add_environment)\n",
    ")\n",
    "\n",
    "\n",
    "NewProtectedAreaExtentSchema(\n",
    "    coverage.pipe(\n",
    "        output,\n",
    "        \"iso_3\",\n",
    "        {},\n",
    "        {},\n",
    "        [\"area\", \"iso_3\", 'total_marine_area'],\n",
    "    )\n",
    ").to_csv(\n",
    "    output_file,\n",
    "    index=True,\n",
    ")\n",
    "coverage.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_oecms = (\n",
    "    sjoin_gdf.groupby([\"iso_3\", \"PA_DEF\"])\n",
    "    .agg({\"PA_DEF\": \"count\"})\n",
    "    .rename(columns={\"PA_DEF\": \"count\"})\n",
    "    .reset_index()\n",
    "    .pivot(index=\"GID_0\", columns=\"PA_DEF\", values=\"count\")\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"0\": \"oecm\", \"1\": \"pa\"})\n",
    ")\n",
    "# ).reset_index().pivot(index=\"iso_3\", columns=\"PA_DEF\", values=\"count\").reset_index(names=[\"PA_DEF\"], level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_oecms[\"oecm_perc\"] = result_oecms[\"oecm\"] / (result_oecms[\"oecm\"] + result_oecms[\"pa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PA_DEF</th>\n",
       "      <th>iso_3</th>\n",
       "      <th>oecm</th>\n",
       "      <th>pa</th>\n",
       "      <th>oecm_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50674.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>SWE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30813.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DEU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23703.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>EST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>FIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18427.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CAN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12566.0</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>GBR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11712.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11154.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CHE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10632.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NZL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10205.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PA_DEF iso_3  oecm       pa  oecm_perc\n",
       "180      USA   0.0  50674.0   0.000000\n",
       "161      SWE   0.0  30813.0   0.000000\n",
       "44       DEU   0.0  23703.0   0.000000\n",
       "55       EST   0.0  20579.0   0.000000\n",
       "57       FIN   0.0  18427.0   0.000000\n",
       "29       CAN   2.0  12566.0   0.000159\n",
       "61       GBR   0.0  11712.0   0.000000\n",
       "9        AUS   0.0  11154.0   0.000000\n",
       "30       CHE   0.0  10632.0   0.000000\n",
       "130      NZL   0.0  10205.0   0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_oecms.sort_values(\"pa\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_area = pd.concat(data)[['iso_3', 'year', 'area']].groupby(['iso_3', 'year']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result_area.merge(result_oecms, on=\"iso_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sjoin_gdf to file\n",
    "sjoin_gdf.to_file(pipe_dir.get_processed_step_path(current_step).joinpath(\"tpa_sjoin.shp\"), driver=\"ESRI Shapefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjoin_gdf = gpd.read_file(pipe_dir.get_processed_step_path(current_step).joinpath(\"tpa_sjoin.shp\")).pipe(clean_geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WDPAID', 'WDPA_PID', 'PA_DEF', 'NAME', 'DESIG_ENG', 'IUCN_CAT',\n",
       "       'MARINE', 'GIS_AREA', 'STATUS', 'STATUS_YR', 'PARENT_ISO', 'index_righ',\n",
       "       'COUNTRY', 'GID_0', 'area_km2', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sjoin_gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PA_DEF</th>\n",
       "      <th>GID_0</th>\n",
       "      <th>oecm</th>\n",
       "      <th>pa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AND</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ARG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ATA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ATG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11234.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PA_DEF GID_0  oecm       pa\n",
       "0        AFG   0.0     25.0\n",
       "1        AGO   0.0     37.0\n",
       "2        ALB   0.0    117.0\n",
       "3        AND   0.0     23.0\n",
       "4        ARE   0.0     54.0\n",
       "5        ARG   0.0    403.0\n",
       "6        ARM   0.0     68.0\n",
       "7        ATA   0.0      9.0\n",
       "8        ATG   0.0     10.0\n",
       "9        AUS   0.0  11234.0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_oecms = (\n",
    "    sjoin_gdf.groupby([\"GID_0\", \"PA_DEF\"])\n",
    "    .agg({\"PA_DEF\": \"count\"})\n",
    "    .rename(columns={\"PA_DEF\": \"count\"})\n",
    "    .reset_index()\n",
    "    .pivot(index=\"GID_0\", columns=\"PA_DEF\", values=\"count\")\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"0\": \"oecm\", \"1\": \"pa\"})\n",
    ")\n",
    "# ).reset_index().pivot(index=\"iso_3\", columns=\"PA_DEF\", values=\"count\").reset_index(names=[\"PA_DEF\"], level=0, drop=True)\n",
    "\n",
    "result_oecms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def process_mpa_data(\n",
    "#     gdf: gpd.GeoDataFrame, loop: list[int], by: list[str], aggfunc: dict\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"process protected planet data. relevant for acc coverage extent by year indicator.\"\"\"\n",
    "#     # we split the data by =< year so we can acumulate the coverage\n",
    "#     base = split_by_year(gdf)\n",
    "\n",
    "#     result_to_iter = pd.concat(base, ignore_index=True).copy()\n",
    "\n",
    "#     with tqdm(total=len(loop)) as pbar:  # we create a progress bar\n",
    "#         new_df = await asyncio.gather(\n",
    "#             *(spatial_dissolve_chunk(year, result_to_iter, pbar, by, aggfunc) for year in loop)\n",
    "#         )\n",
    "#     return pd.concat(\n",
    "#         [base[0].pipe(calculate_area, \"area\", None).drop(columns=[\"geometry\"]), *new_df],\n",
    "#         ignore_index=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data = await process_mpa_data(\n",
    "#     eez_mpas_data_join.pipe(add_location_iso).pipe(assign_iso3),\n",
    "#     range(2011, time.localtime().tm_year + 1),\n",
    "#     [\"PA_DEF\", \"iso_3\"],\n",
    "#     {\"protectedAreasCount\": \"sum\"},\n",
    "# )\n",
    "# coverage = (\n",
    "#     final_data.pipe(calculate_global_area, [\"year\", \"PA_DEF\"], {\"area\": \"sum\"}, \"iso_3\")\n",
    "#     .pipe(separate_parent_iso, \"iso_3\")\n",
    "#     .pipe(add_region_iso, \"iso_3\")\n",
    "#     .replace(\n",
    "#         {\n",
    "#             \"iso_3\": {\n",
    "#                 \"ATA\": \"ABNJ\",\n",
    "#                 \"COK\": \"NZL\",\n",
    "#                 \"IOT\": \"GBR\",\n",
    "#                 \"NIU\": \"NZL\",\n",
    "#                 \"SHN\": \"GBR\",\n",
    "#                 \"SJM\": \"NOR\",\n",
    "#                 \"UMI\": \"USA\",\n",
    "#                 \"NCL\": \"FRA\",\n",
    "#                 \"GIB\": \"GBR\",\n",
    "#             }\n",
    "#         }\n",
    "#     )\n",
    "#     .pipe(calculate_stats_cov, [\"year\", \"PA_DEF\"], \"iso_3\").astype({\"PA_DEF\": int})\n",
    "#     .pipe(add_pa_oecm_percentages)\n",
    "#     .pipe(add_total_marine_area)\n",
    "#     .pipe(coverage_stats2)\n",
    "#     .pipe(calculate_coverage_percentage_mpa)\n",
    "#     .pipe(calculate_global_contribution)\n",
    "#     .pipe(add_is_last_year)\n",
    "#     .pipe(add_environment)\n",
    "# )\n",
    "\n",
    "\n",
    "# NewProtectedAreaExtentSchema(\n",
    "#     coverage.pipe(\n",
    "#         output,\n",
    "#         \"iso_3\",\n",
    "#         {},\n",
    "#         {},\n",
    "#         [\"area\", \"iso_3\", 'total_marine_area'],\n",
    "#     )\n",
    "# ).to_csv(\n",
    "#     output_file,\n",
    "#     index=True,\n",
    "# )\n",
    "# coverage.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
