{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should we save every output as a [geoparquet](https://geoparquet.org/) in the future to improve read performance (reduction 30% read time)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import dotenv  \n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "scripts_dir = Path(\".\").joinpath(\"src\")\n",
    "import sys\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.insert(0, scripts_dir.resolve().as_posix())\n",
    "\n",
    "from helpers.utils import downloadFile, rm_tree, make_archive, writeReadGCP\n",
    "from helpers.settings import get_settings\n",
    "from helpers.file_handler import FileConventionHandler\n",
    "from pipelines.utils import watch\n",
    "from pipelines.processors import (\n",
    "    set_wdpa_id,\n",
    "    protection_level,\n",
    "    status,\n",
    "    create_year,\n",
    "    calculate_area,\n",
    "    get_mpas,\n",
    "    set_location_iso,\n",
    "    set_fps_classes,\n",
    "    filter_by_methodology,\n",
    "    filter_by_terrestrial,\n",
    "    transform_points,\n",
    "    clean_geometries,\n",
    "    simplify_async,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysettings = get_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eez_intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe params\n",
    "force_clean = True\n",
    "step = \"preprocess\"\n",
    "pipe = \"eez\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sources\n",
    "## EEZ\n",
    "EEZ_url = \"https://www.marineregions.org/download_file.php\"\n",
    "EEZ_file_name = \"eez_v11.shp\"\n",
    "EEZ_params = {\"name\": \"World_EEZ_v11_20191118.zip\"}\n",
    "EEZ_headers = {\n",
    "    \"content-type\": \"application/x-www-form-urlencoded\",\n",
    "    \"cookie\": \"PHPSESSID=29190501b4503e4b33725cd6bd01e2c6; vliz_webc=vliz_webc2; jwplayer.captionLabel=Off\",\n",
    "    \"dnt\": \"1\",\n",
    "    \"origin\": \"https://www.marineregions.org\",\n",
    "    \"sec-fetch-dest\": \"document\",\n",
    "    \"sec-fetch-mode\": \"navigate\",\n",
    "    \"sec-fetch-site\": \"same-origin\",\n",
    "    \"sec-fetch-user\": \"?1\",\n",
    "    \"upgrade-insecure-requests\": \"1\",\n",
    "}\n",
    "\n",
    "EEZ_body = {\n",
    "    \"name\": \"Jason\",\n",
    "    \"organisation\": \"skytruth\",\n",
    "    \"email\": \"hello@skytruth.com\",\n",
    "    \"country\": \"Spain\",\n",
    "    \"user_category\": \"academia\",\n",
    "    \"purpose_category\": \"Conservation\",\n",
    "    \"agree\": \"1\",\n",
    "}\n",
    "\n",
    "## High seas\n",
    "hs_url = \"https://www.marineregions.org/download_file.php\"\n",
    "hs_file_name = \"High_seas_v1.shp\"\n",
    "hs_params = {\"name\": \"World_High_Seas_v1_20200826.zip\"}\n",
    "hs_headers = {\n",
    "    \"content-type\": \"application/x-www-form-urlencoded\",\n",
    "    \"cookie\": \"PHPSESSID=29190501b4503e4b33725cd6bd01e2c6; vliz_webc=vliz_webc2; jwplayer.captionLabel=Off\",\n",
    "    \"dnt\": \"1\",\n",
    "    \"origin\": \"https://www.marineregions.org\",\n",
    "    \"sec-fetch-dest\": \"document\",\n",
    "    \"sec-fetch-mode\": \"navigate\",\n",
    "    \"sec-fetch-site\": \"same-origin\",\n",
    "    \"sec-fetch-user\": \"?1\",\n",
    "    \"upgrade-insecure-requests\": \"1\",\n",
    "}\n",
    "hs_body = {\n",
    "    \"name\": \"Jason\",\n",
    "    \"organisation\": \"skytruth\",\n",
    "    \"email\": \"hello@skytruth.com\",\n",
    "    \"country\": \"Spain\",\n",
    "    \"user_category\": \"academia\",\n",
    "    \"purpose_category\": \"Conservation\",\n",
    "    \"agree\": \"1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "\n",
    "output_path = working_folder.get_processed_step_path(step)\n",
    "output_file = working_folder.get_step_fmt_file_path(step, \"shp\")\n",
    "zipped_output_file = working_folder.get_step_fmt_file_path(step, \"zip\", True)\n",
    "remote_path = working_folder.get_remote_path(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "## download files EEZ & High seas\n",
    "downloadFile(\n",
    "    EEZ_url,\n",
    "    input_path,\n",
    "    EEZ_body,\n",
    "    EEZ_params,\n",
    "    EEZ_headers,\n",
    "    overwrite=force_clean,\n",
    ")\n",
    "downloadFile(hs_url, input_path, hs_body, hs_params, hs_headers, overwrite=force_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unzip file if needed & load data\n",
    "unziped_folders = []\n",
    "for idx, path in enumerate(input_path.glob(\"*.zip\")):\n",
    "    unziped_folder = temp_working_path.joinpath(path.stem)\n",
    "    print(unziped_folder)\n",
    "\n",
    "    if unziped_folder.exists() and force_clean:\n",
    "        rm_tree(unziped_folder)\n",
    "\n",
    "    shutil.unpack_archive(path, unziped_folder)\n",
    "\n",
    "    files = [gpd.read_file(file) for file in unziped_folder.rglob(\"*.shp\") if \"boundaries\" not in file.stem]\n",
    "    unziped_folders.append(\n",
    "        pd.concat(files)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, gdf in enumerate(unziped_folders):\n",
    "    print(f\"GeoDataFrame {idx} has {len(gdf)} rows and {len(gdf.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data\n",
    "## set the same structure for both datasets updating the high seas one\n",
    "unziped_folders[0] = (\n",
    "    unziped_folders[0]\n",
    "    .rename(\n",
    "        columns={\"name\": \"GEONAME\", \"area_km2\": \"AREA_KM2\", \"mrgid\": \"MRGID\"},\n",
    "    )\n",
    "    .assign(\n",
    "        POL_TYPE=\"High Seas\",\n",
    "        ISO_SOV1=\"ABNJ\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# merge datasets\n",
    "df = pd.concat(unziped_folders, ignore_index=True)\n",
    "\n",
    "df.drop(\n",
    "    columns=list(\n",
    "        set(df.columns)\n",
    "        - set(\n",
    "            [\n",
    "                \"MRGID\",\n",
    "                \"GEONAME\",\n",
    "                \"POL_TYPE\",\n",
    "                \"ISO_SOV1\",\n",
    "                \"ISO_SOV2\",\n",
    "                \"ISO_SOV3\",\n",
    "                \"AREA_KM2\",\n",
    "                \"geometry\",\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "gpd.GeoDataFrame(\n",
    "    df,\n",
    "    crs=unziped_folders[0].crs,\n",
    ").to_file(filename=output_file.as_posix(), driver=\"ESRI Shapefile\")\n",
    "\n",
    "# zip data\n",
    "make_archive(output_path, zipped_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean unzipped files\n",
    "rm_tree(temp_working_path) if temp_working_path.exists() else None\n",
    "rm_tree(output_path) if output_path.exists() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "## load zipped file to GCS\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=zipped_output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries gadm intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe params\n",
    "force_clean = True\n",
    "step = \"preprocess\"\n",
    "pipe = \"gadm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "\n",
    "output_path = working_folder.get_processed_step_path(step)\n",
    "output_file = working_folder.get_step_fmt_file_path(step, \"shp\")\n",
    "zipped_output_file = working_folder.get_step_fmt_file_path(step, \"zip\", True)\n",
    "remote_path = working_folder.get_remote_path(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gadm_url = \"https://geodata.ucdavis.edu/gadm/gadm4.1/gadm_410-levels.zip\"\n",
    "gadm_file_name = \"gadm_410-levels.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "input_file = downloadFile(\n",
    "    gadm_url,\n",
    "    input_path,\n",
    "    overwrite=force_clean,\n",
    "    file=gadm_file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /home/sofia/dev/skytruth-30x30/data/data/gadm/raw/temp_preprocess/gadm_410-levels\n",
      "Removed existing folder: /home/sofia/dev/skytruth-30x30/data/data/gadm/raw/temp_preprocess/gadm_410-levels\n",
      "Unpacked /home/sofia/dev/skytruth-30x30/data/data/gadm/raw/gadm_410-levels.zip to /home/sofia/dev/skytruth-30x30/data/data/gadm/raw/temp_preprocess/gadm_410-levels\n"
     ]
    }
   ],
   "source": [
    "# Check if there is a zip file in the input_path\n",
    "zip_file = next(input_path.glob(\"*.zip\"), None)\n",
    "if zip_file:\n",
    "    unziped_folder = temp_working_path.joinpath(zip_file.stem)\n",
    "    print(f\"Processing: {unziped_folder}\")\n",
    "\n",
    "    if unziped_folder.exists() and force_clean:\n",
    "        shutil.rmtree(unziped_folder)\n",
    "        print(f\"Removed existing folder: {unziped_folder}\")\n",
    "\n",
    "    # Unpack the archive\n",
    "    shutil.unpack_archive(zip_file, unziped_folder)\n",
    "    print(f\"Unpacked {zip_file} to {unziped_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GeoPackage: /home/sofia/dev/skytruth-30x30/data/data/gadm/raw/temp_preprocess/gadm_410-levels/gadm_410-levels.gpkg\n",
      "Selected layer: ADM_0\n"
     ]
    }
   ],
   "source": [
    "# Select data adm_0, dissolve and save as shp\n",
    "geopackage_file = next(unziped_folder.rglob(\"*.gpkg\"), None)\n",
    "\n",
    "if geopackage_file:\n",
    "    print(f\"Found GeoPackage: {geopackage_file}\")\n",
    "\n",
    "    # Specify the layer to read\n",
    "    layer_name = \"ADM_0\"\n",
    "    gdf = gpd.read_file(geopackage_file, layer=layer_name)\n",
    "    print(f\"Selected layer: {layer_name}\")   \n",
    "    \n",
    "else:\n",
    "    print(\"No GeoPackage file found in the unzipped folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_gid_0_and_country(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Updates the GID_0 and COUNTRY values in the GeoDataFrame for dependent territories \n",
    "    with the GID_0 and COUNTRY of their sovereign parent countries.\n",
    "\n",
    "    Parameters:\n",
    "    gdf (gpd.GeoDataFrame): The input GeoDataFrame with 'GID_0' and 'COUNTRY' columns.\n",
    "\n",
    "    Returns:\n",
    "    gpd.GeoDataFrame: The GeoDataFrame with updated 'GID_0' and 'COUNTRY' values for dependent territories.\n",
    "    \"\"\"\n",
    "    # Load the dependency_to_parent mapping\n",
    "    with open(scripts_dir.joinpath('data_commons/data/dependency_to_parent.json'), 'r') as json_file:\n",
    "        dependency_to_parent = json.load(json_file)\n",
    "\n",
    "    # Map GID_0 to the updated values\n",
    "    gdf['GID_0'] = gdf['GID_0'].map(lambda x: dependency_to_parent.get(x, (x, x))[0])\n",
    "    \n",
    "    # Update COUNTRY based on the updated GID_0\n",
    "    gdf['COUNTRY'] = gdf['GID_0'].map(lambda x: {v[0]: v[1] for k, v in dependency_to_parent.items()}.get(x, gdf['COUNTRY'].loc[gdf['GID_0'] == x].values[0]))\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def add_translations(df, translations_csv_path):\n",
    "    translations_df = pd.read_csv(translations_csv_path, keep_default_na=False, na_values=[])\n",
    "    \n",
    "    df = df.merge(translations_df[['code', 'name_es', 'name_fr']], left_on='GID_0', right_on='code', how='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign territories to their parent countries\n",
    "gdf_updated = update_gid_0_and_country(gdf)\n",
    "\n",
    "# Dissolve by country\n",
    "gdf_updated = gdf_updated.dissolve(by='COUNTRY').reset_index()\n",
    "\n",
    "# Calculate area\n",
    "gdf_updated = gdf_updated.pipe(calculate_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download country translations\n",
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "\n",
    "translations_csv_url = \"vizzuality_processed_data/gadm/preprocess/locations_translated.csv\"\n",
    "translations_csv_output = input_path.joinpath(translations_csv_url.split(\"/\")[-1])\n",
    "\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=translations_csv_url,\n",
    "    file=translations_csv_output,\n",
    "    operation=\"r\",\n",
    ")\n",
    "\n",
    "translations_path = input_path.joinpath('locations_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>geometry</th>\n",
       "      <th>GID_0</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>name_es</th>\n",
       "      <th>name_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>MULTIPOLYGON (((63.61425 29.46993, 63.60868 29...</td>\n",
       "      <td>AFG</td>\n",
       "      <td>644050.28</td>\n",
       "      <td>Afganistán</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>MULTIPOLYGON (((19.27804 40.50524, 19.28189 40...</td>\n",
       "      <td>ALB</td>\n",
       "      <td>28689.62</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Albanie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>MULTIPOLYGON (((2.84535 36.74691, 2.84597 36.7...</td>\n",
       "      <td>DZA</td>\n",
       "      <td>2311455.23</td>\n",
       "      <td>Argelia</td>\n",
       "      <td>Algérie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>POLYGON ((1.61725 42.62406, 1.63334 42.62553, ...</td>\n",
       "      <td>AND</td>\n",
       "      <td>450.35</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>MULTIPOLYGON (((11.78636 -16.78001, 11.78478 -...</td>\n",
       "      <td>AGO</td>\n",
       "      <td>1251701.39</td>\n",
       "      <td>Angola</td>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>MULTIPOLYGON (((103.46895 9.25602, 103.46736 9...</td>\n",
       "      <td>VNM</td>\n",
       "      <td>330364.87</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>MULTIPOLYGON (((-16.83569 22.15403, -16.83597 ...</td>\n",
       "      <td>ESH</td>\n",
       "      <td>267892.77</td>\n",
       "      <td>Sahara Occidental</td>\n",
       "      <td>Sahara occidental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>MULTIPOLYGON (((42.1618 15.03042, 42.16236 15....</td>\n",
       "      <td>YEM</td>\n",
       "      <td>453741.18</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>Yémen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>POLYGON ((25.87834 -17.97218, 25.87034 -17.970...</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>753990.33</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Zambie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>POLYGON ((32.70425 -18.96022, 32.70537 -18.965...</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>391234.88</td>\n",
       "      <td>Zimbabue</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            COUNTRY                                           geometry GID_0  \\\n",
       "0       Afghanistan  MULTIPOLYGON (((63.61425 29.46993, 63.60868 29...   AFG   \n",
       "1           Albania  MULTIPOLYGON (((19.27804 40.50524, 19.28189 40...   ALB   \n",
       "2           Algeria  MULTIPOLYGON (((2.84535 36.74691, 2.84597 36.7...   DZA   \n",
       "3           Andorra  POLYGON ((1.61725 42.62406, 1.63334 42.62553, ...   AND   \n",
       "4            Angola  MULTIPOLYGON (((11.78636 -16.78001, 11.78478 -...   AGO   \n",
       "..              ...                                                ...   ...   \n",
       "199         Vietnam  MULTIPOLYGON (((103.46895 9.25602, 103.46736 9...   VNM   \n",
       "200  Western Sahara  MULTIPOLYGON (((-16.83569 22.15403, -16.83597 ...   ESH   \n",
       "201           Yemen  MULTIPOLYGON (((42.1618 15.03042, 42.16236 15....   YEM   \n",
       "202          Zambia  POLYGON ((25.87834 -17.97218, 25.87034 -17.970...   ZMB   \n",
       "203        Zimbabwe  POLYGON ((32.70425 -18.96022, 32.70537 -18.965...   ZWE   \n",
       "\n",
       "       area_km2            name_es            name_fr  \n",
       "0     644050.28         Afganistán        Afghanistan  \n",
       "1      28689.62            Albania            Albanie  \n",
       "2    2311455.23            Argelia            Algérie  \n",
       "3        450.35            Andorra            Andorre  \n",
       "4    1251701.39             Angola             Angola  \n",
       "..          ...                ...                ...  \n",
       "199   330364.87            Vietnam            Vietnam  \n",
       "200   267892.77  Sahara Occidental  Sahara occidental  \n",
       "201   453741.18              Yemen              Yémen  \n",
       "202   753990.33             Zambia             Zambie  \n",
       "203   391234.88           Zimbabue           Zimbabwe  \n",
       "\n",
       "[204 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add translations for country names\n",
    "gdf_translated = add_translations(gdf_updated, translations_path).drop(columns=['code'])\n",
    "gdf_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 204/204 [05:58<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "final_gadm = await simplify_async(gdf_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file\n",
    "final_gadm.to_file(output_file.as_posix(), driver=\"ESRI Shapefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip data\n",
    "make_archive(output_path, zipped_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load zipped file to GCS\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=zipped_output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mpa Atlas intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_clean = True\n",
    "step = \"preprocess\"\n",
    "pipe = \"mpaatlas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source\n",
    "mpaatlas_url = \"https://guide.mpatlas.org/api/v1/zone/geojson\"\n",
    "mpaatlas_file_name = \"mpatlas_assess_zone.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "\n",
    "output_path = working_folder.get_processed_step_path(step)\n",
    "output_file = working_folder.get_step_fmt_file_path(step, \"shp\")\n",
    "zipped_output_file = working_folder.get_step_fmt_file_path(step, \"zip\", True)\n",
    "remote_path = working_folder.get_remote_path(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "input_file = downloadFile(\n",
    "    mpaatlas_url,\n",
    "    input_path,\n",
    "    overwrite=force_clean,\n",
    "    file=mpaatlas_file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not force_clean and zipped_output_file.exists():\n",
    "    print(f\"File {zipped_output_file} already exists\")\n",
    "\n",
    "# Transform data\n",
    "gdf = gpd.read_file(input_file)\n",
    "\n",
    "df = (gdf\n",
    "      .pipe(set_wdpa_id)\n",
    "      .pipe(protection_level)\n",
    "      .pipe(status)\n",
    "      .pipe(create_year))\n",
    "\n",
    "df.drop(\n",
    "    columns=list(\n",
    "        set(df.columns)\n",
    "        - set(\n",
    "            [\n",
    "                \"wdpa_id\",\n",
    "                \"mpa_zone_id\", \n",
    "                \"name\",\n",
    "                \"designation\",\n",
    "                \"sovereign\",\n",
    "                \"establishment_stage\",\n",
    "                \"protection_mpaguide_level\",\n",
    "                \"protection_level\",\n",
    "                \"year\",\n",
    "                \"geometry\",\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    inplace=True,\n",
    ")\n",
    "df.rename(columns={\"sovereign\": \"location_id\", \"wdpa_pid\": \"wdpa_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3376415/3601108936.py:5: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  ).to_file(filename=output_file.as_posix(), driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
      "/home/sofia/miniforge3/envs/skytruth/lib/python3.12/site-packages/pyogrio/raw.py:709: RuntimeWarning: Normalized/laundered field name: 'mpa_zone_id' to 'mpa_zone_i'\n",
      "  ogr_write(\n",
      "/home/sofia/miniforge3/envs/skytruth/lib/python3.12/site-packages/pyogrio/raw.py:709: RuntimeWarning: Normalized/laundered field name: 'designation' to 'designatio'\n",
      "  ogr_write(\n",
      "/home/sofia/miniforge3/envs/skytruth/lib/python3.12/site-packages/pyogrio/raw.py:709: RuntimeWarning: Normalized/laundered field name: 'location_id' to 'location_i'\n",
      "  ogr_write(\n",
      "/home/sofia/miniforge3/envs/skytruth/lib/python3.12/site-packages/pyogrio/raw.py:709: RuntimeWarning: Normalized/laundered field name: 'establishment_stage' to 'establishm'\n",
      "  ogr_write(\n",
      "/home/sofia/miniforge3/envs/skytruth/lib/python3.12/site-packages/pyogrio/raw.py:709: RuntimeWarning: Normalized/laundered field name: 'protection_mpaguide_level' to 'protection'\n",
      "  ogr_write(\n",
      "/home/sofia/miniforge3/envs/skytruth/lib/python3.12/site-packages/pyogrio/raw.py:709: RuntimeWarning: Normalized/laundered field name: 'protection_level' to 'protecti_1'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "#save data\n",
    "gpd.GeoDataFrame(\n",
    "    df,\n",
    "    crs=gdf.crs,\n",
    ").to_file(filename=output_file.as_posix(), driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "\n",
    "make_archive(output_path, zipped_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "## load zipped file to GCS\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=zipped_output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean unzipped files\n",
    "rm_tree(temp_working_path) if temp_working_path.exists() else None\n",
    "rm_tree(output_path) if output_path.exists() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protected seas intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "force_clean = True\n",
    "step = \"preprocess\"\n",
    "pipe = \"protectedseas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "\n",
    "output_path = working_folder.get_processed_step_path(step)\n",
    "output_file = working_folder.get_step_fmt_file_path(step, \"shp\")\n",
    "zipped_output_file = working_folder.get_step_fmt_file_path(step, \"zip\", True)\n",
    "remote_path = working_folder.get_remote_path(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_csv_url = \"ProtectedSeas/ProtectedSeas_06142023.csv\"\n",
    "ps_csv_output = input_path.joinpath(ps_csv_url.split(\"/\")[-1])\n",
    "\n",
    "ps_geometries_url = (\n",
    "    \"ProtectedSeas/ProtectedSeas_ProtectedSeas_06142023_shp_ProtectedSeas_06142023_shp.zip\"\n",
    ")\n",
    "ps_geometries_output = input_path.joinpath(ps_geometries_url.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not force_clean and zipped_output_file.exists():\n",
    "    print(f\"File {zipped_output_file} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the data\n",
    "\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=ps_csv_url,\n",
    "    file=ps_csv_output,\n",
    "    operation=\"r\",\n",
    ")\n",
    "\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=ps_geometries_url,\n",
    "    file=ps_geometries_output,\n",
    "    operation=\"r\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip shapefile\n",
    "shutil.unpack_archive(ps_geometries_output, temp_working_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "# TODO: Modify the preprocessing steps so we do not eliminate the geometries that does not intersect with MPAs - do to a change in the processing methodology\n",
    "data_table = pd.read_csv(ps_csv_output).pipe(get_mpas).pipe(set_location_iso).pipe(set_fps_classes)\n",
    "\n",
    "data_table.drop(\n",
    "    columns=data_table.columns.difference(\n",
    "        [\n",
    "            \"site_id\",\n",
    "            \"iso\",\n",
    "            \"FPS_cat\",\n",
    "            \"site_name\",\n",
    "            \"country\",\n",
    "            \"wdpa_id\",\n",
    "            \"removal_of_marine_life_is_prohibited\",\n",
    "            \"total_area\",\n",
    "        ]\n",
    "    ),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "data_table.rename(columns={\"removal_of_marine_life_is_prohibited\": \"FPS\"}, inplace=True)\n",
    "\n",
    "# load geoemtries & merge\n",
    "\n",
    "gdf = gpd.read_file(ps_geometries_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "gdf.merge(data_table, how=\"inner\", left_on=\"SITE_ID\", right_on=\"site_id\").drop(\n",
    "    columns=[\"SITE_ID\", \"SITE_NAME\"]\n",
    ").to_file(filename=output_file.as_posix(), driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "\n",
    "# zip data\n",
    "make_archive(output_path, zipped_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean unzipped files\n",
    "rm_tree(temp_working_path) if temp_working_path.exists() else None\n",
    "rm_tree(output_path) if output_path.exists() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "## load zipped file to GCS\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=zipped_output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mpas protected planet intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_clean = True\n",
    "step = \"preprocess\"\n",
    "pipe = \"mpa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpa_url = \"https://www.protectedplanet.net/downloads\"\n",
    "mpa_body = {\n",
    "    \"domain\": \"general\",\n",
    "    \"format\": \"shp\",\n",
    "    \"token\": \"marine\",\n",
    "    \"id\": 21961,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'marine-shp', 'title': 'WDPA_WDOECM_Sep2024_Public_marine_shp', 'url': 'https://d1gam3xoknrgr2.cloudfront.net/current/WDPA_WDOECM_Sep2024_Public_marine_shp.zip', 'hasFailed': False, 'token': 'marine'}\n"
     ]
    }
   ],
   "source": [
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "\n",
    "output_path = working_folder.get_processed_step_path(step)\n",
    "output_file = working_folder.get_step_fmt_file_path(step, \"shp\")\n",
    "zipped_output_file = working_folder.get_step_fmt_file_path(step, \"zip\", True)\n",
    "remote_path = working_folder.get_remote_path(step)\n",
    "\n",
    "# download data\n",
    "r = requests.post(url=mpa_url, data=mpa_body)\n",
    "r.raise_for_status()\n",
    "\n",
    "download_url = r.json().get(\"url\")\n",
    "input_file_name = f'{r.json().get(\"title\")}.zip'\n",
    "print(r.json())\n",
    "\n",
    "input_file =  downloadFile(\n",
    "    url=download_url,\n",
    "    output_path=input_path,\n",
    "    overwrite=force_clean,\n",
    "    file=input_file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip file twice due how data is provisioned by protected planet\n",
    "shutil.unpack_archive(\n",
    "    input_file,\n",
    "    temp_working_path,\n",
    "    \"zip\",\n",
    ")\n",
    "\n",
    "for file in temp_working_path.glob(\"*.zip\"):\n",
    "    shutil.unpack_archive(file, temp_working_path.joinpath(file.stem), \"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data & Transform it\n",
    "unziped_folders = []\n",
    "for file in temp_working_path.glob(\"*/*.shp\"):\n",
    "    df = (\n",
    "        gpd.read_file(file)\n",
    "        .pipe(filter_by_methodology)\n",
    "        .pipe(transform_points)\n",
    "        .pipe(clean_geometries)\n",
    "    )\n",
    "    unziped_folders.append(df)\n",
    "\n",
    "# merge datasets\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pd.concat(unziped_folders, ignore_index=True),\n",
    "    crs=unziped_folders[0].crs,\n",
    ")\n",
    "\n",
    "gdf.drop(\n",
    "    columns=list(\n",
    "        set(gdf.columns)\n",
    "        - set(\n",
    "            [\n",
    "                \"geometry\",\n",
    "                \"WDPAID\",\n",
    "                \"WDPA_PID\",\n",
    "                \"PA_DEF\",\n",
    "                \"NAME\",\n",
    "                \"PARENT_ISO\",\n",
    "                \"DESIG_ENG\",\n",
    "                \"IUCN_CAT\",\n",
    "                \"STATUS\",\n",
    "                \"STATUS_YR\",\n",
    "                \"GIS_M_AREA\",\n",
    "                \"AREA_KM2\",\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    inplace=True,\n",
    ")\n",
    "gdf[\"WDPAID\"] = pd.to_numeric(gdf[\"WDPAID\"], downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data & zip it\n",
    "gdf.to_file(filename=output_file, driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "\n",
    "make_archive(output_path, zipped_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "## load zipped file to GCS\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=zipped_output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vizzuality_processed_data/mpa/preprocess/mpa_preprocess.zip'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean unzipped files\n",
    "rm_tree(temp_working_path) if temp_working_path.exists() else None\n",
    "rm_tree(output_path) if output_path.exists() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pas protected planet intermediate terrestrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_clean = True\n",
    "step = \"preprocess\"\n",
    "pipe = \"mpa-terrestrial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpa_url = \"https://www.protectedplanet.net/downloads\"\n",
    "mpa_body = {\n",
    "    \"domain\": \"general\",\n",
    "    \"format\": \"shp\",\n",
    "    \"token\": \"wdpa\",\n",
    "    \"id\": 76011,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "\n",
    "output_path = working_folder.get_processed_step_path(step)\n",
    "output_file = working_folder.get_step_fmt_file_path(step, \"gpkg\")\n",
    "zipped_output_file = working_folder.get_step_fmt_file_path(step, \"zip\", True)\n",
    "remote_path = working_folder.get_remote_path(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "r = requests.post(url=mpa_url, data=mpa_body)\n",
    "r.raise_for_status()\n",
    "\n",
    "download_url = r.json().get(\"url\")\n",
    "input_file_name = f'{r.json().get(\"title\")}.zip'\n",
    "print(r.json())\n",
    "\n",
    "input_file = downloadFile(\n",
    "    url=download_url,\n",
    "    output_path=input_path,\n",
    "    overwrite=force_clean,\n",
    "    file=input_file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip file twice due how data is provisioned by protected planet\n",
    "shutil.unpack_archive(\n",
    "    input_file,\n",
    "    temp_working_path,\n",
    "    \"zip\",\n",
    ")\n",
    "\n",
    "for file in temp_working_path.glob(\"*.zip\"):\n",
    "    shutil.unpack_archive(file, temp_working_path.joinpath(file.stem), \"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data & Transform it\n",
    "unziped_folders = []\n",
    "for file in temp_working_path.glob(\"*/*.shp\"):\n",
    "    df = (\n",
    "        gpd.read_file(file)\n",
    "        .pipe(filter_by_methodology)\n",
    "        .pipe(filter_by_terrestrial)\n",
    "        .pipe(transform_points)\n",
    "        .pipe(clean_geometries)\n",
    "    )\n",
    "    unziped_folders.append(df)\n",
    "\n",
    "# merge datasets\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pd.concat(unziped_folders, ignore_index=True),\n",
    "    crs=unziped_folders[0].crs,\n",
    ")\n",
    "\n",
    "gdf.drop(\n",
    "    columns=list(\n",
    "        set(gdf.columns)\n",
    "        - set(\n",
    "            [\n",
    "                \"geometry\",\n",
    "                \"WDPAID\",\n",
    "                \"WDPA_PID\",\n",
    "                \"PA_DEF\",\n",
    "                \"NAME\",\n",
    "                \"PARENT_ISO\",\n",
    "                \"DESIG_ENG\",\n",
    "                \"IUCN_CAT\",\n",
    "                \"STATUS\",\n",
    "                \"STATUS_YR\",\n",
    "                \"GIS_AREA\",\n",
    "                \"MARINE\",\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    inplace=True,\n",
    ")\n",
    "gdf[\"WDPAID\"] = pd.to_numeric(gdf[\"WDPAID\"], downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 85/292261 [00:00<14:27, 336.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                               | 661/292261 [00:07<145:23:41,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██                                                                                                                                               | 4100/292261 [00:10<00:50, 5746.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▋                                                                                                                                         | 13673/292261 [00:12<02:06, 2195.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████████████████▋                                                                                                                  | 60200/292261 [00:20<01:26, 2696.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████████████▏                                                                                                               | 65454/292261 [00:22<02:10, 1744.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████████████████▋                                                                                                 | 94837/292261 [00:27<00:41, 4733.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████████████████████████                                                                                              | 100205/292261 [00:28<00:47, 4031.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████████████████▎                                                                                           | 104962/292261 [00:29<00:43, 4304.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████████████████████████▎                                                                                    | 119249/292261 [00:32<00:35, 4855.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████████████████████████████████▋                                                                             | 134186/292261 [00:35<00:52, 3035.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████████████████████████████████▎                                                                      | 147855/292261 [00:38<00:42, 3390.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████████████████████████████████████▋                                                                   | 154770/292261 [00:40<00:37, 3677.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████████████████████████████████████▌                                                                  | 156511/292261 [00:40<01:10, 1915.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████████████████████████████████████████▍                                                               | 162422/292261 [00:42<00:31, 4181.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████████████████████████████████▌                                                            | 168614/292261 [00:43<00:55, 2234.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 199564/292261 [00:49<00:19, 4753.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 205065/292261 [00:50<00:27, 3198.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 219986/292261 [00:53<00:17, 4065.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 246638/292261 [00:58<00:10, 4368.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 271598/292261 [01:03<00:06, 3242.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 275485/292261 [01:03<00:04, 3707.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 278285/292261 [01:04<00:02, 6507.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 290011/292261 [01:11<00:00, 5892.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 292261/292261 [03:13<00:00, 1507.66it/s]\n"
     ]
    }
   ],
   "source": [
    "final_wdpa_terrestrial = await simplify_async(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data & zip it\n",
    "final_wdpa_terrestrial.to_file(\n",
    "    filename=output_file,\n",
    "    driver=\"GPKG\",\n",
    "    layer=\"name\",\n",
    "    encoding=\"utf-8\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sofia/dev/skytruth-30x30/data/data/mpa-terrestrial/processed/preprocess/mpa-terrestrial_preprocess.gpkg')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_wdpa_terrestrial['MARINE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "## load zipped file to GCS\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean unzipped files\n",
    "rm_tree(temp_working_path) if temp_working_path.exists() else None\n",
    "rm_tree(output_path) if output_path.exists() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protected planet intermediate all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_clean = True\n",
    "step = \"preprocess\"\n",
    "pipe = \"pa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpa_url = \"https://www.protectedplanet.net/downloads\"\n",
    "mpa_body = {\n",
    "    \"domain\": \"general\",\n",
    "    \"format\": \"shp\",\n",
    "    \"token\": \"wdpa\",\n",
    "    \"id\": 76011,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "\n",
    "output_path = working_folder.get_processed_step_path(step)\n",
    "output_file = working_folder.get_step_fmt_file_path(step, \"gpkg\")\n",
    "zipped_output_file = working_folder.get_step_fmt_file_path(step, \"zip\", True)\n",
    "remote_path = working_folder.get_remote_path(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'wdpa-shp', 'title': 'WDPA_Sep2024_Public_shp', 'url': 'https://d1gam3xoknrgr2.cloudfront.net/current/WDPA_Sep2024_Public_shp.zip', 'hasFailed': False, 'token': 'wdpa'}\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "r = requests.post(url=mpa_url, data=mpa_body)\n",
    "r.raise_for_status()\n",
    "\n",
    "download_url = r.json().get(\"url\")\n",
    "input_file_name = f'{r.json().get(\"title\")}.zip'\n",
    "print(r.json())\n",
    "\n",
    "# input_file = downloadFile(\n",
    "#     url=download_url,\n",
    "#     output_path=input_path,\n",
    "#     overwrite=force_clean,\n",
    "#     file=input_file_name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip file twice due how data is provisioned by protected planet\n",
    "shutil.unpack_archive(\n",
    "    input_file,\n",
    "    temp_working_path,\n",
    "    \"zip\",\n",
    ")\n",
    "\n",
    "for file in temp_working_path.glob(\"*.zip\"):\n",
    "    shutil.unpack_archive(file, temp_working_path.joinpath(file.stem), \"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data & Transform it\n",
    "unziped_folders = []\n",
    "for file in temp_working_path.glob(\"*/*.shp\"):\n",
    "    df = (\n",
    "        gpd.read_file(file)\n",
    "        .pipe(filter_by_methodology)\n",
    "        .pipe(transform_points)\n",
    "        .pipe(clean_geometries)\n",
    "    )\n",
    "    unziped_folders.append(df)\n",
    "\n",
    "# merge datasets\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    pd.concat(unziped_folders, ignore_index=True),\n",
    "    crs=unziped_folders[0].crs,\n",
    ")\n",
    "\n",
    "gdf.drop(\n",
    "    columns=list(\n",
    "        set(gdf.columns)\n",
    "        - set(\n",
    "            [\n",
    "                \"geometry\",\n",
    "                \"WDPAID\",\n",
    "                \"WDPA_PID\",\n",
    "                \"PA_DEF\",\n",
    "                \"NAME\",\n",
    "                \"PARENT_ISO\",\n",
    "                \"DESIG_ENG\",\n",
    "                \"IUCN_CAT\",\n",
    "                \"STATUS\",\n",
    "                \"STATUS_YR\",\n",
    "                \"GIS_AREA\",\n",
    "                \"GIS_M_AREA\",\n",
    "                \"MARINE\",\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    inplace=True,\n",
    ")\n",
    "gdf[\"WDPAID\"] = pd.to_numeric(gdf[\"WDPAID\"], downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 298912/298912 [03:53<00:00, 1277.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                                                                            | 1817/298912 [00:11<03:42, 1338.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▉                                                                                                                                                           | 3731/298912 [00:12<03:25, 1433.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▏                                                                                                                                                          | 4223/298912 [00:12<01:23, 3536.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████                                                                                                                                                      | 11698/298912 [00:15<04:00, 1191.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████                                                                                                                            | 61318/298912 [00:27<03:03, 1298.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████████▉                                                                                                                         | 66972/298912 [00:29<02:28, 1566.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████████████████████▌                                                                                                         | 96777/298912 [00:35<01:04, 3139.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████████████████████████████▏                                                                                                     | 102462/298912 [00:37<00:46, 4270.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████████████████████▍                                                                                                   | 106818/298912 [00:38<01:33, 2059.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████████████████████████████████▉                                                                                            | 121477/298912 [00:41<01:20, 2212.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████████████████████████████████                                                                                        | 129353/298912 [00:44<01:10, 2404.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████████████████████████████████▊                                                                                    | 136616/298912 [00:46<01:06, 2457.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████████████████████▊                                                                              | 148130/298912 [00:50<01:02, 2399.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████████████████████████████████████████████▍                                                                            | 151376/298912 [00:51<01:09, 2121.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████████████████████████████████████                                                                        | 160280/298912 [00:53<01:55, 1197.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 164997/298912 [00:54<01:16, 1760.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 166577/298912 [00:55<01:03, 2072.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                 | 172769/298912 [00:56<01:01, 2037.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 174238/298912 [00:57<00:30, 4024.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                  | 201035/298912 [01:03<00:17, 5566.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 205073/298912 [01:04<00:17, 5454.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 210501/298912 [01:05<00:27, 3184.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 225210/298912 [01:08<00:17, 4259.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 225947/298912 [01:09<00:48, 1498.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 229699/298912 [01:10<00:23, 2896.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 252333/298912 [01:15<00:15, 3001.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Polygon' object has no attribute 'geoms'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 277458/298912 [01:21<00:07, 2831.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 281117/298912 [01:22<00:12, 1449.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 284183/298912 [01:23<00:04, 3294.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 296106/298912 [01:32<00:00, 3532.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 298912/298912 [03:53<00:00,  2.59it/s]"
     ]
    }
   ],
   "source": [
    "final_wdpa = await simplify_async(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data & zip it\n",
    "final_wdpa.to_file(\n",
    "    filename=output_file,\n",
    "    driver=\"GPKG\",\n",
    "    layer=\"name\",\n",
    "    encoding=\"utf-8\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD\n",
    "## load zipped file to GCS\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=remote_path,\n",
    "    file=output_file,\n",
    "    operation=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean unzipped files\n",
    "rm_tree(temp_working_path) if temp_working_path.exists() else None\n",
    "rm_tree(output_path) if output_path.exists() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Habitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_clean = True\n",
    "step = \"preprocess\"\n",
    "pipe = \"habitats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "habitats_download_url = \"https://habitats.oceanplus.org/downloads/global_statistics.zip\"\n",
    "Mangroves_download_url = \"https://mangrove-atlas-api.herokuapp.com/admin/widget_protected_areas.csv\"\n",
    "mangroves_request_headers = {\n",
    "    \"Cookie\": \"_mangrove_atlas_api_session=fJuobvI2fH42WfGfMtRTp%2BksIDdPEpY6DG8uCuITsENtrRGG4AA3nYEeAI7dytzpK%2F0dGIHq84O54MRr6eiPgiwCYXp2XP4IzXM40dFt%2FI6hoB0WXC%2Fwrd81XreNnMZiSEE6IVT5R0fqMcmsZdPn53u0A1d4CGU3FfliOZuWkckBuA%2F7C4upBGuSS8817LqOh1slG%2BsEOGp3nk7WX4fMoPbsHWtARfFwdfoAHz448LO7uWuZdyiu7YOrS0ZxOZEb9JZ8hcUJph4pBFofZLpOvtQQutgZY21T5bhQ7Kwfl56e6Qr0SZ%2B8sIzMfky3h%2FjOA6DNTLoy%2BZLiZBAgFHlTYm2JwlwqWgAZU8D7cE7Zn%2Fxgf3LFF9pZ9Fe3QG4c8LIwH%2FxqjEd8GsZAhBMgBWbxubigQ9gZssZt6CIO--7qiVsTAT8JAKj1jU--U7TI%2Fz9c151bfD8iZdkBDw%3D%3D\"\n",
    "}\n",
    "seamounts_download_url = \"https://datadownload-production.s3.amazonaws.com/ZSL002_ModelledSeamounts2011_v1.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = FileConventionHandler(pipe)\n",
    "input_path = working_folder.pipe_raw_path\n",
    "temp_working_path = working_folder.get_temp_file_path(step)\n",
    "\n",
    "output_path = working_folder.get_processed_step_path(step)\n",
    "output_file = working_folder.get_step_fmt_file_path(step, \"shp\")\n",
    "zipped_output_file = working_folder.get_step_fmt_file_path(step, \"zip\", True)\n",
    "remote_path = working_folder.get_remote_path(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seamounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seamounts_path = input_path.joinpath(\"seamounts\")\n",
    "input_seamounts_path.mkdir(parents=True, exist_ok=True)\n",
    "# download data\n",
    "input_file_name = \"seamounts.zip\"\n",
    "input_file = downloadFile(\n",
    "    url=seamounts_download_url,\n",
    "    output_path=input_seamounts_path,\n",
    "    overwrite=force_clean,\n",
    "    file=input_file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip data\n",
    "shutil.unpack_archive(\n",
    "    input_file,\n",
    "    temp_working_path,\n",
    "    \"zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_working_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first =gpd.read_file(next(temp_working_path.rglob(\"*SeamountsBaseArea.shp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not force_clean and zipped_output_file.exists():\n",
    "    print(f\"File {zipped_output_file} already exists\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
