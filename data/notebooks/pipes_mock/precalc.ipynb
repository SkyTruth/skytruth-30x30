{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "scripts_dir = Path(\"../..\").joinpath(\"src\")\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.insert(0, scripts_dir.resolve().as_posix())\n",
    "\n",
    "from helpers.strapi import Strapi\n",
    "from helpers.settings import get_settings, Settings\n",
    "from helpers.file_handler import FileConventionHandler\n",
    "from helpers.utils import download_and_unzip_if_needed, writeReadGCP\n",
    "\n",
    "from pipelines.output_schemas import (\n",
    "    FPLSchema,\n",
    "    ProtectionLevelSchema,\n",
    "    MPAsSchema,\n",
    "    HabitatsSchema,\n",
    "    LocationSchema,\n",
    "    ProtectedAreaExtentSchema,\n",
    ")\n",
    "from pipelines.processors import (\n",
    "    add_envelope,\n",
    "    add_location_iso,\n",
    "    expand_multiple_locations,\n",
    "    add_region_iso,\n",
    "    calculate_eez_area,\n",
    "    add_bbox,\n",
    "    add_groups_and_members,\n",
    "    add_location_name,\n",
    "    output,\n",
    "    clean_geometries,\n",
    "    filter_by_exluding_propossed_mpas,\n",
    "    spatial_join,\n",
    "    process_mpa_data,\n",
    "    assign_iso3,\n",
    "    calculate_global_area,\n",
    "    separate_parent_iso,\n",
    "    calculate_stats_cov,\n",
    "    coverage_stats,\n",
    "    mpaatlas_filter_stablishment,\n",
    "    process_mpaatlas_data,\n",
    "    calculate_stats,\n",
    "    fix_monaco,\n",
    "    batch_export,\n",
    "    calculate_area,\n",
    "    define_is_child,\n",
    "    set_child_id,\n",
    "    add_child_parent_relationship,\n",
    "    columns_to_lower,\n",
    "    extract_wdpaid_mpaatlas,\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"fiona\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysettings = get_settings()\n",
    "prev_step = \"preprocess\"\n",
    "current_step = \"stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<helpers.strapi.Strapi at 0x780ee9f63b00>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strapi setup\n",
    "strapi = Strapi(url=mysettings.STRAPI_URL)\n",
    "strapi.login(jwt=mysettings.STRAPI_JWT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after generated the locations file for the first time:\n",
    "location_code = pd.read_csv(mysettings.DATA_DIR.joinpath(\"eez/processed/stats/locations_code.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations (eez + regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mambauser/data/eez/processed/eez_preprocess.zip\n",
      "/home/mambauser/data/eez/processed/preprocess\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mambauser/data/eez/processed/preprocess')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = \"eez\"\n",
    "strapi_collection = \"\"\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "\n",
    "output_file = pipe_dir.get_processed_step_path(current_step).joinpath(\"locations.json\")\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir, prev_step, mysettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = (\n",
    "    gpd.read_file(pipe_dir.get_step_fmt_file_path(prev_step, \"shp\"))\n",
    "    .pipe(add_envelope)\n",
    "    .pipe(add_location_iso)\n",
    "    .pipe(expand_multiple_locations)\n",
    "    .pipe(add_region_iso,'iso')\n",
    "    .pipe(calculate_eez_area)\n",
    "    .pipe(add_bbox)\n",
    "    .pipe(add_groups_and_members)\n",
    "    .pipe(add_location_name)\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"iso\": \"code\",\n",
    "            \"AREA_KM2\": \"totalMarineArea\",\n",
    "            \"location_type\": \"type\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "locations.drop(\n",
    "    columns=list(\n",
    "        set(locations.columns) - \n",
    "        set([\"code\", \"name\", \"totalMarineArea\", \"type\", \"groups\", \"bounds\", \"id\"])),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "output_locations = {\n",
    "    \"version\": 2,\n",
    "    \"data\": {\n",
    "        \"api::location.location\": LocationSchema(pd.DataFrame(locations)).to_dict(\n",
    "            orient=\"index\"\n",
    "        )\n",
    "    },\n",
    "}\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(output_locations, f)\n",
    "\n",
    "del output_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "(locations[['id', 'code']]\n",
    " .to_csv(pipe_dir.get_processed_step_path(current_step)\n",
    "     .joinpath('locations_code.csv'), index=False))\n",
    "\n",
    "del locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.deleteCollectionData(strapi_collection, list(range(1, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.importCollectionData(\n",
    "    strapi_collection,\n",
    "    output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Habitats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The habitat data came from:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = \"habitats\"\n",
    "strapi_collection = ''\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "output_file = pipe_dir.get_step_fmt_file_path(current_step, \"csv\")\n",
    "\n",
    "# Download the habitat file\n",
    "# download_and_unzip_if_needed(pipe_dir, prev_step, mysettings)\n",
    "\n",
    "habitats_intermediate = pd.read_csv(\n",
    "    pipe_dir.processed_path.joinpath(\"habitats4.csv\"), keep_default_na=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "habitat_stats = habitats_intermediate.pipe(\n",
    "    output,\n",
    "    iso_column=\"location_id\",\n",
    "    rep_d={\n",
    "        \"habitat_name\": {\n",
    "            \"saltmarshes\": 1,\n",
    "            \"seagrasses\": 2,\n",
    "            \"warm-water corals\": 3,\n",
    "            \"cold-water corals\": 4,\n",
    "            \"mangroves\": 5,\n",
    "            \"seamounts\": 6,\n",
    "        },\n",
    "        \"protected_area\": {\"\": 0},\n",
    "    },\n",
    "    rename={\n",
    "        \"protected_area\": \"protectedArea\",\n",
    "        \"total_area\": \"totalArea\",\n",
    "        \"habitat_name\": \"habitat\",\n",
    "    },\n",
    "    drop_cols=[\"location_id\"],\n",
    ")\n",
    "HabitatsSchema(habitat_stats).to_csv(\n",
    "    output_file.as_posix(), index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.deleteCollectionData(strapi_collection, list(range(1, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.importCollectionData(\n",
    "    strapi_collection,\n",
    "    output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage stats - Mpas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the intermediate data from eez, in order to create a dataset that can be used as a land mask.\n",
    "The steps are:\n",
    "1. Load eez\n",
    "2. Spatial inner Join the eez dataset with the Mpas one\n",
    "3. Assign the location iso\n",
    "4. dissolve by location iso and cummulative year\n",
    "5. calculate the area for global regions and eez countries\n",
    "6. prepare the data to be ingested in strapi\n",
    "7. upload the data to strapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mambauser/data/eez/processed/eez_preprocess.zip\n",
      "/home/mambauser/data/eez/processed/preprocess\n",
      "/home/mambauser/data/mpa/processed/mpa_preprocess.zip\n",
      "/home/mambauser/data/mpa/processed/preprocess\n"
     ]
    }
   ],
   "source": [
    "pipe = \"mpa\"\n",
    "strapi_collection = \"\"\n",
    "\n",
    "pipe_dir_eez = FileConventionHandler(\"eez\")\n",
    "pipe_dir_mpas = FileConventionHandler(pipe)\n",
    "output_file = pipe_dir_mpas.get_processed_step_path(current_step).joinpath(\n",
    "    \"mpa_landmask_strapi.csv\"\n",
    ")\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir_eez, prev_step, mysettings)\n",
    "# Download the mpas file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir_mpas, prev_step, mysettings)\n",
    "\n",
    "# Load the data\n",
    "eez = gpd.read_file(pipe_dir_eez.get_step_fmt_file_path(prev_step, \"shp\")).pipe(clean_geometries)\n",
    "mpas = gpd.read_file(pipe_dir_mpas.get_step_fmt_file_path(prev_step, \"shp\")).pipe(clean_geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 281/282 [06:12<01:03, 63.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [06:33<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n",
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eez_mpas_data_join = await spatial_join(eez, mpas.pipe(filter_by_exluding_propossed_mpas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get an idea of the spatial join results\n",
    "eez_mpas_data_join.pipe(add_location_iso).pipe(assign_iso3).to_file(\n",
    "    pipe_dir_mpas.get_processed_step_path(current_step).joinpath(\"mpas_sjoin.shp\"), driver=\"ESRI Shapefile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "100%|██████████| 14/14 [03:03<00:00, 13.12s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "  7%|▋         | 1/14 [01:14<16:05, 74.30s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      " 14%|█▍        | 2/14 [01:19<06:42, 33.52s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      " 21%|██▏       | 3/14 [01:45<05:30, 30.01s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      " 29%|██▊       | 4/14 [02:00<04:02, 24.29s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      " 43%|████▎     | 6/14 [02:03<01:29, 11.15s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      " 50%|█████     | 7/14 [02:12<01:13, 10.47s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      " 57%|█████▋    | 8/14 [02:16<00:50,  8.40s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      " 64%|██████▍   | 9/14 [02:57<01:33, 18.63s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      " 79%|███████▊  | 11/14 [02:59<00:28,  9.46s/it]DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "100%|█████████▉| 281/282 [00:20<00:02,  2.84s/it]"
     ]
    }
   ],
   "source": [
    "final_data = await process_mpa_data(\n",
    "    eez_mpas_data_join.pipe(add_location_iso).pipe(assign_iso3),\n",
    "    range(2011, time.localtime().tm_year + 1),\n",
    "    [\"PA_DEF\", \"iso_3\"],\n",
    "    {\"protectedAreasCount\": \"sum\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = (\n",
    "    final_data.pipe(calculate_global_area, [\"year\", \"PA_DEF\"], {\"area\": \"sum\"}, \"iso_3\")\n",
    "    .pipe(separate_parent_iso, \"iso_3\")\n",
    "    .pipe(add_region_iso, \"iso_3\")\n",
    "    .replace(\n",
    "        {\n",
    "            \"iso_3\": {\n",
    "                \"ATA\": \"ABNJ\",\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "                \"GIB\": \"GBR\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .pipe(calculate_stats_cov, [\"year\", \"PA_DEF\"], \"iso_3\")\n",
    "    .pipe(coverage_stats)\n",
    ")\n",
    "\n",
    "ProtectedAreaExtentSchema(\n",
    "    coverage.pipe(\n",
    "        output,\n",
    "        \"iso_3\",\n",
    "        {\"PA_DEF\": {\"0\": 2, \"1\": 1}},\n",
    "        {\"PARENT_NAME\": \"location\", \"PA_DEF\": \"protection_status\"},\n",
    "        [\"area\", \"iso_3\"],\n",
    "    )\n",
    ").to_csv(\n",
    "    output_file,\n",
    "    index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.deleteCollectionData(strapi_collection, list(range(1, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.importCollectionData(\n",
    "    strapi_collection,\n",
    "    output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mpa atlas - country stats Fully or highly protected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the intermediate data from eez, in order to create a dataset that can be used as a land mask.\n",
    "The steps are:\n",
    "1. Load eez\n",
    "2. Spatial inner Join the eez dataset with the Mpaatlas one\n",
    "3. iso assign using the sovereign one provided by mpaatlas\n",
    "4. dissolve by location\n",
    "5. calculate the area for global regions and eez countries ussing mollwide projection\n",
    "6. prepare the data to be ingested in strapi\n",
    "7. upload the data to strapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mambauser/data/eez/processed/eez_preprocess.zip\n",
      "/home/mambauser/data/eez/processed/preprocess\n",
      "/home/mambauser/data/mpaatlas/processed/mpaatlas_preprocess.zip\n",
      "/home/mambauser/data/mpaatlas/processed/preprocess\n"
     ]
    }
   ],
   "source": [
    "pipe = \"mpaatlas\"\n",
    "strapi_collection = \"mpaa-protection-level-stat\"\n",
    "\n",
    "pipe_dir_eez = FileConventionHandler(\"eez\")\n",
    "pipe_dir_mpaatlas = FileConventionHandler(pipe)\n",
    "output_file = pipe_dir_mpaatlas.get_processed_step_path(current_step).joinpath(\n",
    "    \"mpaatlas_protection_level.csv\"\n",
    ")\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir_eez, prev_step, mysettings)\n",
    "# Download the mpas file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir_mpaatlas, prev_step, mysettings)\n",
    "\n",
    "# Load the data\n",
    "eez = gpd.read_file(pipe_dir_eez.get_step_fmt_file_path(prev_step, \"shp\")).pipe(clean_geometries)\n",
    "mpaatlas_intermediate = gpd.read_file(\n",
    "    pipe_dir_mpaatlas.get_step_fmt_file_path(prev_step, \"shp\")\n",
    ").pipe(clean_geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/282 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:27<00:00,  4.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:27<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'shapely.geometry.base.GeometrySequence'>\n"
     ]
    }
   ],
   "source": [
    "eez_mpaatlas_data_join = await spatial_join(\n",
    "    eez, mpaatlas_intermediate.pipe(mpaatlas_filter_stablishment)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get an idea of the spatial join results\n",
    "# eez_mpaatlas_data_join.to_file(\n",
    "#     pipe_dir_mpaatlas.get_processed_step_path(current_step).joinpath(\"mpaatlas_sjoin.shp\"),\n",
    "#     driver=\"ESRI Shapefile\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n"
     ]
    }
   ],
   "source": [
    "eez_mpaatlas_data_join.dissolve(by=[\"protecti_1\", \"location_i\"], aggfunc={\"name\": \"count\"}).reset_index().to_file(\n",
    "pipe_dir_mpaatlas.get_processed_step_path(current_step).joinpath(\"mpaatlas_sjoin_dissolved.shp\"),\n",
    "driver=\"ESRI Shapefile\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pyproj:PROJ_ERROR: proj_create: unrecognized format / unknown name\n"
     ]
    }
   ],
   "source": [
    "result = (\n",
    "    eez_mpaatlas_data_join.pipe(process_mpaatlas_data)\n",
    "    .pipe(calculate_global_area, gby_col=[\"protecti_1\"], iso_column=\"location_i\")\n",
    "    .pipe(separate_parent_iso)\n",
    "    .replace(\n",
    "        {\n",
    "            \"location_i\": {\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .pipe(add_region_iso, iso_column=\"location_i\")\n",
    "    .pipe(calculate_stats, gby_col=[\"protecti_1\"], iso_column=\"location_i\")\n",
    "    .pipe(fix_monaco, iso_column=\"location_i\", area_column=\"area_km2\")\n",
    "    .pipe(\n",
    "        output,\n",
    "        iso_column=\"location_i\",\n",
    "        rep_d={\n",
    "            \"protecti_1\": {\n",
    "                \"fully or highly protected\": 1,\n",
    "                \"less protected or unknown\": 2,\n",
    "            }\n",
    "        },\n",
    "        rename={\"protecti_1\": \"mpaa_protection_level\", \"area_km2\": \"area\"},\n",
    "        drop_cols=[],\n",
    "    )\n",
    ")\n",
    "\n",
    "ProtectionLevelSchema(result[~result.location.isna()].assign(year=2023)).to_csv(\n",
    "    output_file, index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.deleteCollectionData(strapi_collection, list(range(1, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.importCollectionData(\n",
    "    strapi_collection,\n",
    "    output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protected seas  - fishing protection level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n"
     ]
    }
   ],
   "source": [
    "pipe = \"protectedseas\"\n",
    "strapi_collection = \"fishing-protection-level-stat\"\n",
    "\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "input_file = pipe_dir.get_processed_step_path(prev_step).joinpath(\"protectedseas_stats.xlsx\")\n",
    "output_file = pipe_dir.get_processed_step_path(current_step).joinpath(\"lfp.csv\")\n",
    "\n",
    "# Download the protected seas file && unzip it\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=\"vizzuality_processed_data/protectedseas/preprocess/protectedseas_stats.xlsx\",\n",
    "    file=input_file,\n",
    "    operation=\"r\",\n",
    ")\n",
    "\n",
    "# Load the data\n",
    "protectedseas_intermediate = pd.read_excel(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mambauser/src/pipelines/processors.py:685: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(rep_d)\n"
     ]
    }
   ],
   "source": [
    "final = (\n",
    "    protectedseas_intermediate.replace(\n",
    "        {\n",
    "            \"iso_sov\": {\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "            },\n",
    "            \"lfp\": {\n",
    "                5: \"highly\",\n",
    "                4: \"highly\",\n",
    "                3: \"moderately\",\n",
    "                2: \"less\",\n",
    "                1: \"less\",\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    .pipe(\n",
    "        calculate_global_area,\n",
    "        gby_col=[\"lfp\"],\n",
    "        iso_column=\"iso_sov\",\n",
    "        agg_ops={\"area_sqkm\": \"sum\", \"total_area\": \"max\"},\n",
    "    )\n",
    "    .pipe(add_region_iso, iso_column=\"iso_sov\")\n",
    "    .pipe(\n",
    "        calculate_stats,\n",
    "        gby_col=[\"lfp\"],\n",
    "        ops={\"area_sqkm\": \"sum\", \"total_area\": \"max\"},\n",
    "        iso_column=\"iso_sov\",\n",
    "    )\n",
    "    .pipe(lambda x: x.assign(pct=round(x.area_sqkm / x.total_area, 2)))\n",
    "    .pipe(\n",
    "        output,\n",
    "        iso_column=\"iso_sov\",\n",
    "        rep_d={\n",
    "            \"lfp\": {\n",
    "                \"highly\": 1,\n",
    "                \"moderately\": 2,\n",
    "                \"less\": 3,\n",
    "            }\n",
    "        },\n",
    "        rename={\"lfp\": \"fishing_protection_level\", \"area_sqkm\": \"area\"},\n",
    "        drop_cols=[\"iso_sov\", \"total_area\"],\n",
    "    )\n",
    ")\n",
    "FPLSchema(final[final.location.notna()]).to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.deleteCollectionData(strapi_collection, list(range(1, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strapi.importCollectionData(\n",
    "    strapi_collection,\n",
    "    output_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country mpas detail table data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1- lower case the columns   \n",
    "2- separate location that its regime is in dispute or on join regime  \n",
    "3- calcualte area for mpaatlas data  \n",
    "4- rename columns for merge  \n",
    "5- merge maaatlas and mpa data identifying the source  \n",
    "6- identify child resources and set them as childs  \n",
    "7- calculate bbox  \n",
    "8- set child resources  \n",
    "9- prepare output for batch export  \n",
    "10- upload data to strapi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google.auth.transport.requests:Making request: POST https://oauth2.googleapis.com/token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mambauser/data/mpa/processed/mpa_preprocess.zip\n",
      "/home/mambauser/data/mpa/processed/preprocess\n",
      "/home/mambauser/data/mpaatlas/processed/mpaatlas_preprocess.zip\n",
      "/home/mambauser/data/mpaatlas/processed/preprocess\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mambauser/data/mpaatlas/processed/preprocess')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = \"mpa\"\n",
    "strapi_collection_mpas = \"mpa\"\n",
    "\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "pipe_dir_mpaatlas = FileConventionHandler(\"mpaatlas\")\n",
    "output_file_mpas = pipe_dir.get_processed_step_path(current_step).joinpath(\"mpa_detail.csv\")\n",
    "\n",
    "# Download the protected atlas file && unzip it\n",
    "download_and_unzip_if_needed(pipe_dir, prev_step, mysettings)\n",
    "# Download the mpaatlas file \n",
    "download_and_unzip_if_needed(pipe_dir_mpaatlas, prev_step, mysettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "mpa_intermediate = gpd.read_file(pipe_dir.get_step_fmt_file_path(prev_step, \"shp\")).pipe(\n",
    "    clean_geometries\n",
    ")\n",
    "mpaatlas_intermediate = gpd.read_file(\n",
    "    pipe_dir_mpaatlas.get_step_fmt_file_path(prev_step, \"shp\")\n",
    ").pipe(clean_geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_table = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            (\n",
    "                mpa_intermediate.pipe(columns_to_lower)\n",
    "                .pipe(separate_parent_iso, iso_column=\"parent_iso\")\n",
    "                .rename(\n",
    "                    columns={\n",
    "                        \"parent_iso\": \"iso\",\n",
    "                        \"status_yr\": \"year\",\n",
    "                        \"gis_m_area\": \"area_km2\",\n",
    "                        \"status\": \"establishm\",\n",
    "                    }\n",
    "                )\n",
    "            ).assign(source=\"protected_planet\"),\n",
    "            (\n",
    "                mpaatlas_intermediate.pipe(calculate_area)\n",
    "                .pipe(extract_wdpaid_mpaatlas)\n",
    "                .pipe(separate_parent_iso, iso_column=\"location_i\")\n",
    "                .rename(\n",
    "                    columns={\n",
    "                        \"location_i\": \"iso\",\n",
    "                        \"wdpa_id\": \"wdpa_pid\",\n",
    "                        \"designatio\": \"desig_eng\",\n",
    "                    }\n",
    "                )\n",
    "            ).assign(source=\"mpaatlas\"\n",
    "            ).astype({\"mpa_zone_i\": \"Int64\"}),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .replace(\n",
    "        {\n",
    "            \"iso\": {\n",
    "                \"COK\": \"NZL\",\n",
    "                \"IOT\": \"GBR\",\n",
    "                \"NIU\": \"NZL\",\n",
    "                \"SHN\": \"GBR\",\n",
    "                \"SJM\": \"NOR\",\n",
    "                \"UMI\": \"USA\",\n",
    "                \"NCL\": \"FRA\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    .sort_values(by=[\"wdpa_pid\", \"wdpa_pid\", \"source\"], ascending=[True, True, False])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to be run if things change a lot in the future\n",
    "# iucn_cat = pd.DataFrame(\n",
    "#     {\"slug\": init_table.iucn_cat.dropna().unique(), \"name\": init_table.iucn_cat.dropna().unique()},\n",
    "#     index=pd.Index(np.arange(1, len(init_table.iucn_cat.dropna().unique()) + 1)),\n",
    "# )\n",
    "# iucn_cat.to_csv(pipe_dir.get_processed_step_path(current_step).joinpath(\"iucn_categories.csv\"), index=True)\n",
    "\n",
    "iucn_cat = pd.read_csv(\n",
    "    pipe_dir.get_processed_step_path(current_step).joinpath(\"iucn_categories.csv\"), index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mambauser/src/pipelines/processors.py:660: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  \n",
      "/home/mambauser/src/pipelines/processors.py:685: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "mpa_table = (\n",
    "    init_table.pipe(add_bbox, \"bbox\")\n",
    "    .pipe(define_is_child)\n",
    "    .pipe(set_child_id)\n",
    "    .sort_values(by=[\"wdpaid\", \"is_child\"], ascending=[True, True])\n",
    "    .reset_index(drop=True)\n",
    "    .pipe(\n",
    "        output,\n",
    "        iso_column=\"iso\",\n",
    "        rep_d={\n",
    "            \"status\": {\n",
    "                \"Adopted\": 4,\n",
    "                \"implemented\": 6,\n",
    "                \"Established\": 6,\n",
    "                \"Designated\": 5,\n",
    "                \"Proposed\": 3,\n",
    "                \"Inscribed\": 3,\n",
    "                \"unknown\": 1,\n",
    "            },\n",
    "            \"pa_def\": {\"0\": 2, \"1\": 1},\n",
    "            \"year\": {0: pd.NA},\n",
    "            \"iucn_cat\": dict(\n",
    "                iucn_cat[[\"slug\"]]\n",
    "                .reset_index(drop=False)\n",
    "                .iloc[:, [1, 0]]\n",
    "                .to_dict(orient=\"tight\")[\"data\"]\n",
    "            ),\n",
    "            \"source\": {\"protected_planet\": 3, \"mpaatlas\": 1},\n",
    "            \"protection\": {\n",
    "                \"full\": 3,\n",
    "                \"light\": 4,\n",
    "                \"incompatible\": 5,\n",
    "                \"high\": 6,\n",
    "                \"minimal\": 7,\n",
    "                \"unknown\": 8,\n",
    "                \"unknown/to be determined\": 8,\n",
    "            },\n",
    "            \"establishm\": {\n",
    "                \"actively managed\": 4,\n",
    "                \"implemented\": 6,\n",
    "                \"designated\": 5,\n",
    "                \"Designated\": 5,\n",
    "                \"proposed or committed\": 3,\n",
    "                \"Proposed\": 3,\n",
    "                \"Inscribed\": 3,\n",
    "                \"Established\": 5,\n",
    "                \"Adopted\": 5,\n",
    "                \"unknown\": 1,\n",
    "            },\n",
    "        },\n",
    "        rename={\n",
    "            \"pa_def\": \"protection_status\",\n",
    "            \"area_km2\": \"area\",\n",
    "            \"iucn_cat\": \"mpa_iucn_category\",\n",
    "            \"desig_eng\": \"designation\",\n",
    "            \"protection\": \"mpaa_protection_level\",\n",
    "            \"establishm\": \"mpaa_establishment_stage\",\n",
    "            \"source\": \"data_source\",\n",
    "        },\n",
    "        drop_cols=[\"geometry\", \"iso\", \"protecti_1\"],  # \"WDPAID\",\n",
    "    )\n",
    "    .pipe(add_child_parent_relationship)\n",
    "    .astype(\n",
    "        {\n",
    "            \"year\": \"Int32\",\n",
    "            \"mpa_iucn_category\": \"Int64\",\n",
    "            \"protection_status\": \"Int64\",\n",
    "        }\n",
    "    )\n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpa_table.to_csv(output_file_mpas, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo investigate the issue with area as null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_export(\n",
    "    mpa_table[mpa_table.area.notna()],\n",
    "    5000,\n",
    "    MPAsSchema,\n",
    "    pipe_dir.get_processed_step_path(current_step),\n",
    "    \"mpa_detail\",\n",
    "    format=\"json\",\n",
    "    strapi_colection=strapi_collection_mpas,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code is to be able to identify groups that has wdpa_pid so in the future if needed we could combine the group geometries to generate a wdpa coverage geometry\n",
    "# init_table[\n",
    "#     (\n",
    "#         init_table.sort_values(by=[\"wdpaid\", \"source\"], ascending=[True, False])\n",
    "#         .groupby(\"wdpaid\")\n",
    "#         .transform(\"size\")\n",
    "#         .gt(1)\n",
    "#     )\n",
    "#     & (init_table.wdpa_pid.str.extract(r\"([A-Za-z]+)\", expand=False).notna())\n",
    "# ].groupby(\"wdpaid\")\n",
    "# .geometry.apply(lambda x: x.union_all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload data to strapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<helpers.strapi.Strapi at 0x780ee9f63b00>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strapi.deleteCollectionData(\"mpa\", list(range(1, 18914)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 4):\n",
    "    strapi.importCollectionData(\n",
    "        strapi_collection_mpas,\n",
    "        mpa_folder.joinpath(f\"mpa_join_mpatlas_prot_{i}.csv\"),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
